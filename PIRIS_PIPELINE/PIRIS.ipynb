{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":495.412665,"end_time":"2025-05-05T20:15:27.519443","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-05T20:07:12.106778","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PIRIS + Bayesian Optimization\n**Hyperparameter Tuning for the PIRIS Model using Bayesian Optimization**","metadata":{"id":"0UIesv2RL5xS"}},{"cell_type":"markdown","source":"# 1. Libraries and Setup","metadata":{"id":"WjbIJ5nPLUKQ"}},{"cell_type":"code","source":"# Install Kaleido, required for saving Optuna's Plotly-based visualizations.\n!pip install --target=/kaggle/working kaleido==0.2.1 -q","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:04.693989Z","iopub.execute_input":"2025-10-09T01:59:04.694539Z","iopub.status.idle":"2025-10-09T01:59:11.725668Z","shell.execute_reply.started":"2025-10-09T01:59:04.694518Z","shell.execute_reply":"2025-10-09T01:59:11.724755Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Uncomment to clear the working directory if needed.\n#!rm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:11.727128Z","iopub.execute_input":"2025-10-09T01:59:11.727459Z","iopub.status.idle":"2025-10-09T01:59:11.731113Z","shell.execute_reply.started":"2025-10-09T01:59:11.727437Z","shell.execute_reply":"2025-10-09T01:59:11.730362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\n\n# Core libraries for system, path management, numerical operations, and plotting\nimport os\nimport subprocess\nimport sys\nimport contextlib\nfrom kaggle_secrets import UserSecretsClient\nimport numpy as np\nimport json\nimport pandas as pd\nimport matplotlib.figure\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns\n\n# Machine Learning and Optimization libraries\nimport tensorflow as tf\nfrom sklearn.cluster import kmeans_plusplus # Used to propose initial candidate points\nimport optuna # For hyperparameter optimization\nfrom optuna.samplers import GPSampler\nfrom optuna.visualization import (\n    plot_param_importances,\n    plot_contour\n)\n\n# Utilities for timing, aesthetics, and progress bars\nimport time\nfrom datetime import datetime\nfrom tqdm.notebook import tqdm\nimport warnings\n\nwarnings.filterwarnings(\"ignore\") # Suppress warnings for a cleaner output\noptuna.logging.set_verbosity(optuna.logging.FATAL) # Suppress verbose logging from Optuna","metadata":{"id":"xzoTZHlz6Yn-","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:11.732017Z","iopub.execute_input":"2025-10-09T01:59:11.732497Z","iopub.status.idle":"2025-10-09T01:59:26.222808Z","shell.execute_reply.started":"2025-10-09T01:59:11.732480Z","shell.execute_reply":"2025-10-09T01:59:26.222265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure workspace to save images to a GitHub repository\n\n# --- SETUP AND AUTHENTICATION ---\n# Best practice: use Kaggle Secrets to store your Personal Access Token (PAT)\nuser_secrets = UserSecretsClient()\nGITHUB_PAT = user_secrets.get_secret(\"GITHUB_PAT\")\n\n# Replace with your GitHub username and the target repository\nGITHUB_USER = \"juansebastiangit\"\nGITHUB_REPO = \"Inteligencia_artificial\"\n\n# The path where the repo will be cloned inside the Kaggle environment\nCLONE_PATH = \"/kaggle/working/my_repo\"\n\n# Define the specific folder inside the repo where images will be saved.\n# A timestamp is used to create a unique directory for each run.\nrun_timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\noutput_dir = f\"PIRIS_PIPELINE/Results_from_{run_timestamp}_run\"\n\n# ---  CLONE THE REPOSITORY ---\n# Construct a repository URL with the PAT for authentication.\nrepo_url_with_auth = f\"https://{GITHUB_USER}:{GITHUB_PAT}@github.com/{GITHUB_USER}/{GITHUB_REPO}.git\"\n\n# Clean up any previous clone to ensure a fresh start\nif os.path.exists(CLONE_PATH):\n    subprocess.run([\"rm\", \"-rf\", CLONE_PATH], check=True)\nprint(f\"Cloning repository: {GITHUB_REPO}...\")\n\n# Clone the repository\nsubprocess.run([\"git\", \"clone\", repo_url_with_auth, CLONE_PATH], check=True)\n\n# Navigate into the cloned repository's directory\nos.chdir(CLONE_PATH)\nprint(f\"Successfully cloned and changed directory to: {os.getcwd()}\")\n\n# Create the target directory for this run's images inside the cloned repo.\nos.makedirs(output_dir, exist_ok=True)\nprint(f\"Created target directory for this run: {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:26.223692Z","iopub.execute_input":"2025-10-09T01:59:26.224171Z","iopub.status.idle":"2025-10-09T01:59:32.251207Z","shell.execute_reply.started":"2025-10-09T01:59:26.224150Z","shell.execute_reply":"2025-10-09T01:59:32.250395Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Context manager to disable plots and printing during performance-critical sections\nPLOTTING_DISABLED = False\n\n@contextlib.contextmanager\ndef suppress_output():\n    \"\"\"\n    A robust context manager that suppresses all print statements and\n    disables plotting by setting a global flag that our functions check.\n    \"\"\"\n    global PLOTTING_DISABLED\n    original_plotting_state = PLOTTING_DISABLED\n    original_stdout = sys.stdout\n    \n    try:\n        # Suppress printing by redirecting stdout to null\n        sys.stdout = open(os.devnull, 'w')\n        # Suppress plotting via our robust global flag\n        PLOTTING_DISABLED = True\n        \n        # This is where the code inside the `with` block will run\n        yield\n        \n    finally:\n        # Restore everything to its original state, even if an error occurs\n        sys.stdout.close()\n        sys.stdout = original_stdout\n        PLOTTING_DISABLED = original_plotting_state\n        \n        print(\"\\n--- Console output and plotting RESTORED. ---\\n\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.253155Z","iopub.execute_input":"2025-10-09T01:59:32.253634Z","iopub.status.idle":"2025-10-09T01:59:32.258455Z","shell.execute_reply.started":"2025-10-09T01:59:32.253605Z","shell.execute_reply":"2025-10-09T01:59:32.257735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Simulation Core Functions","metadata":{}},{"cell_type":"markdown","source":"## 2.1. K-Means++ for Initial Position Generation","metadata":{}},{"cell_type":"markdown","source":"**First, we define the spatial boundaries around the surface to generate candidate points.**","metadata":{}},{"cell_type":"code","source":"def calcular_limites_superficie(posiciones, geometria, params, param_tensors, padding=2.0):\n    \"\"\"\n    Calculates the spatial boundaries for a given atomic structure.\n\n    For planar geometries, it computes the (x, y) bounding box with added padding.\n    For 3D geometries, it computes the center of mass. This information is\n    essential for generating initial candidate positions for k-means++.\n\n    Args:\n        posiciones (np.ndarray): An array of shape (N, 3) with the (x, y, z)\n                                 coordinates of the surface atoms.\n        geometria (str): The geometry type of the sample ('planar' or '3D').\n        params (dict): Dictionary of simulation parameters.\n        param_tensors (dict): Dictionary of simulation parameters as TensorFlow tensors.\n        padding (float): A margin in Angstroms to add to the boundaries of planar structures.\n\n    Returns:\n        dict: A dictionary containing information for candidate point selection, with keys:\n            'tipo' (str): The geometry type ('planar' or '3D').\n            'limite' (tuple): A tuple containing ((x_min, x_max), (y_min, y_max)) for\n                            planar geometries, or the (x, y, z) center for 3D geometries.\n            'escala' (float): A characteristic length scale for the system, used as a\n                            baseline for hyperparameter optimization.\n    \"\"\"\n    if posiciones.ndim != 2 or posiciones.shape[1] < 2:\n        raise ValueError(\"The positions array must have a shape of (N, 2) or (N, 3).\")\n\n    ion_type = params['ion_type']\n    ion_index = param_tensors['type_map'].lookup(tf.constant([ion_type]))[0]\n        \n    if geometria==\"planar\":\n        # Extract x and y coordinates\n        x_coords = posiciones[:, 0]\n        y_coords = posiciones[:, 1]\n        \n        # Find min and max values\n        x_min, x_max = np.min(x_coords), np.max(x_coords)\n        y_min, y_max = np.min(y_coords), np.max(y_coords)\n        \n        # Apply padding\n        limites_x = (x_min - padding, x_max + padding)\n        limites_y = (y_min - padding, y_max + padding)\n\n        # Define a characteristic length scale for Optuna's optimization.\n        # This scale is related to the van der Waals radius of the strongest interaction.\n        max_epsilon = 0.0\n        escala_caracteristica = 0.0\n        surface_atom_types = [t for t in params['atom_types'] if t != ion_type]\n        \n        for atom_type in surface_atom_types:\n            surface_index = param_tensors['type_map'].lookup(tf.constant(atom_type))\n            \n            epsilon = param_tensors['epsilon_matrix'][ion_index][surface_index].numpy()\n            if epsilon > max_epsilon:\n                max_epsilon = epsilon\n                escala_caracteristica = param_tensors['sigma_matrix'][ion_index][surface_index].numpy()\n        \n        if escala_caracteristica == 0.0: # Fallback if no surface atoms are found\n            escala_caracteristica = param_tensors['sigma_matrix'][ion_index][ion_index].numpy()\n        \n        \n        print(f\"Calculated structure boundaries:\")\n        print(f\"  - X Range (with padding): ({limites_x[0]:.2f}, {limites_x[1]:.2f})\")\n        print(f\"  - Y Range (with padding): ({limites_y[0]:.2f}, {limites_y[1]:.2f})\")\n        info_k_means = {\n            \"tipo\": \"planar\",\n            \"limite\": (limites_x, limites_y),\n            \"escala\": escala_caracteristica\n        }\n        return info_k_means\n        \n    elif geometria==\"3D\":\n        centro = np.mean(posiciones, axis=0)\n        \n        # For 3D models, the scale is determined by the maximum distance from the nanoparticle's center.\n        distancias_al_centro = np.linalg.norm(posiciones - centro, axis=1)\n        escala_caracteristica = np.max(distancias_al_centro)\n        info_k_means = {\n            \"tipo\":\"3D\",\n            \"limite\": centro,\n            \"escala\": escala_caracteristica\n        }\n        return info_k_means\n    else:\n        raise ValueError(f\"Geometry type '{geometria}' is not supported.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.259222Z","iopub.execute_input":"2025-10-09T01:59:32.259441Z","iopub.status.idle":"2025-10-09T01:59:32.274404Z","shell.execute_reply.started":"2025-10-09T01:59:32.259418Z","shell.execute_reply":"2025-10-09T01:59:32.273696Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**With the boundaries calculated, we generate a grid of candidate starting points.**","metadata":{}},{"cell_type":"code","source":"def starting_point_suggestions(info_k_means, puntos_por_eje):\n    \"\"\"\n    Generates candidate points for k-means++ to select from.\n\n    Args:\n        info_k_means (dict): Dictionary containing boundary information from `calcular_limites_superficie`.\n        puntos_por_eje (int): The number of points to generate along each axis or for the sphere.\n\n    Returns:\n        np.ndarray: For planar geometry, a grid of possible (x,y) points.\n                    For 3D geometry, an array of direction vectors on a unit sphere.\n    \"\"\"\n\n    tipo = info_k_means[\"tipo\"]\n    if tipo == \"planar\":\n        limites_x, limites_y = info_k_means[\"limite\"]\n        # Generate points along each axis using the calculated boundaries\n        x_coords = np.linspace(limites_x[0], limites_x[1], puntos_por_eje)\n        y_coords = np.linspace(limites_y[0], limites_y[1], puntos_por_eje)\n        \n        # Create the grid using meshgrid\n        xx, yy = np.meshgrid(x_coords, y_coords)\n        \n        # Flatten and combine into an array of (N, 2) coordinates\n        options = np.vstack([xx.ravel(), yy.ravel()]).T\n        \n        print(f\"Grid of {options.shape[0]} candidate positions created.\")\n        return options\n    elif tipo == \"3D\":\n        # Generate random vectors and normalize them to get points on a unit sphere\n        options = np.random.randn(puntos_por_eje, 3)\n        options /= np.linalg.norm(options, axis=1, keepdims=True)\n        print(f\"Set of {options.shape[0]} candidate direction vectors created.\")\n        return options # These are our candidate direction vectors\n    else:\n        raise ValueError(\"Unrecognized configuration shape.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.275119Z","iopub.execute_input":"2025-10-09T01:59:32.275349Z","iopub.status.idle":"2025-10-09T01:59:32.287698Z","shell.execute_reply.started":"2025-10-09T01:59:32.275329Z","shell.execute_reply":"2025-10-09T01:59:32.286964Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Finally, we use the k-means++ algorithm to select a diverse set of starting points from the candidates.**","metadata":{}},{"cell_type":"code","source":"def generate_xy(options, k_simulaciones, num_ni_por_simulacion, random_seed=42):\n    \"\"\"\n    Selects `k_simulaciones` sets of `num_ni_por_simulacion` initial positions using k-means++.\n\n    Args:\n        options (np.ndarray): Array of candidate positions. Shape (N, 2) for planar, or (N, 3)\n                                for 3D unit vectors.\n        k_simulaciones (int): The number of initial configurations to generate.\n        num_ni_por_simulacion (int): The number of ions in each simulation/configuration.\n        random_seed (int): Seed for reproducibility.\n\n    Returns:\n        list: A list of `k_simulaciones` arrays. Each array represents an initial configuration\n              and has a shape of (num_ni_por_simulacion, 2) for planar or (num_ni_por_simulacion, 3)\n              for 3D geometries.\n    \"\"\"\n    \n    total_puntos = k_simulaciones * num_ni_por_simulacion\n    puntos_seleccionados, _ = kmeans_plusplus(options, n_clusters=total_puntos, random_state=random_seed)\n    configuracion = np.array_split(puntos_seleccionados, k_simulaciones)\n    return configuracion","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.288761Z","iopub.execute_input":"2025-10-09T01:59:32.289016Z","iopub.status.idle":"2025-10-09T01:59:32.300934Z","shell.execute_reply.started":"2025-10-09T01:59:32.288984Z","shell.execute_reply":"2025-10-09T01:59:32.300367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2. Ion Placement and Adsorption Setup","metadata":{"id":"_B2jlQzIQy-J"}},{"cell_type":"markdown","source":"**The initial distance of the ions from the surface is treated as a hyperparameter to be optimized.**","metadata":{}},{"cell_type":"code","source":"def build_ions(configuracion, factor_opt, info_k_means):\n    \"\"\"\n    Generates the full 3D coordinates of ions to be adsorbed.\n\n    This function combines the pre-selected initial (x, y) positions or direction vectors\n    with a distance factor to create the final 3D starting positions.\n\n    Args:\n        configuracion (np.ndarray): An array with a set of pre-selected initial positions/vectors.\n        factor_opt (float): A distance scaling factor optimized by Optuna.\n        info_k_means (dict): Dictionary containing boundary and scale information.\n\n    Returns:\n        np.ndarray: An array of shape (num_ni, 3) with the full (x, y, z) ion positions.\n    \"\"\"\n\n    # Extract the characteristic length scale from the info dictionary\n    escala = info_k_means[\"escala\"]\n    # Convert this scale into a concrete distance using the Optuna factor\n    distancia = escala * factor_opt\n    \n    if info_k_means[\"tipo\"] == \"planar\":\n        num_ni = configuracion.shape[0]\n        # Create a z-column with the same distance value for all ions\n        z_column = np.full((num_ni, 1), distancia)\n        \n        # Concatenate the (x, y) positions with the z-column\n        ion_positions = np.hstack([configuracion, z_column])\n        return ion_positions\n        \n    elif info_k_means[\"tipo\"] == \"3D\":\n        centro = info_k_means[\"limite\"]\n        # The distance acts as a radius from the nanoparticle's center\n        ion_positions = centro + distancia * configuracion\n        return ion_positions\n    \n    else:\n        raise ValueError(\"Unrecognized configuration shape.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.301567Z","iopub.execute_input":"2025-10-09T01:59:32.301721Z","iopub.status.idle":"2025-10-09T01:59:32.315083Z","shell.execute_reply.started":"2025-10-09T01:59:32.301709Z","shell.execute_reply":"2025-10-09T01:59:32.314391Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3. Loss Function Definition for Training and Evaluation","metadata":{}},{"cell_type":"markdown","source":"**Training Loss: A combination of physical potential and a PRI regularizer.**","metadata":{}},{"cell_type":"code","source":"# Combined Lennard-Jones and Coulomb potential function\n@tf.function\ndef physical_potential(r, epsilon, sigma, q_i, q_j, k_e):\n    \"\"\"\n    Calculates the physical potential between two sets of particles.\n    \"\"\"\n    sr6 = tf.math.pow(sigma / r, 6)\n    sr12 = tf.math.pow(sr6, 2)\n    lj = 4.0 * epsilon * (sr12 - sr6)\n    coulomb = k_e * q_i * q_j / tf.maximum(r, 1e-10)\n    return lj + coulomb\n\n# Function to calculate the self and cross Information Potential\n@tf.function\ndef calculate_cross_information_potential(points1, points2, sigma):\n    \"\"\"\n    Calculates the Cross Information Potential (CIP) between two sets of points.\n    If points1 and points2 are the same, this calculates the self Information Potential (IP).\n    \"\"\"\n    diff = tf.expand_dims(points1, 1) - tf.expand_dims(points2, 0)\n    sq_dists = tf.reduce_sum(tf.square(diff), axis=-1)\n    kernel_matrix = tf.exp(-sq_dists / (2.0 * sigma**2))\n    return tf.reduce_mean(kernel_matrix)\n    \n# The main training loss function\n@tf.function\ndef get_training_loss(positions, elements, ion_positions, pri_weight, lambda_pri, sigma_pri, ion_type, param_tensors):\n    \"\"\"\n    Calculates the total system energy, combining physical potentials and a PRI regularizer.\n\n    Args:\n        positions (tf.Tensor): Tensor with surface atom positions (num_atoms, 3).\n        elements (tf.Tensor): Tensor with atom type labels for the surface (num_atoms,).\n        ion_positions (tf.Tensor): Tensor with ion positions (num_ions, 3).\n        pri_weight (tf.Tensor): Scalar hyperparameter for the weight of the PRI regularization term.\n        lambda_pri (tf.Tensor): Scalar hyperparameter for the Cauchy-Schwarz divergence term in PRI.\n        sigma_pri (tf.Tensor): Scalar hyperparameter for the RBF kernel width in PRI.\n        ion_type (str): String identifier for the adsorbing ion species.\n        param_tensors (dict): Dictionary of simulation parameters as TensorFlow tensors.\n\n    Returns:\n        tf.Tensor: The total loss for the system (a scalar).\n        tf.Tensor: The total energy per ion (a vector of shape (num_ions,)).\n    \"\"\"\n\n    # --- Get indices for each atom type ---\n    surface_indices = param_tensors['type_map'].lookup(elements)\n    ion_index = param_tensors['type_map'].lookup(tf.constant([ion_type]))[0]\n    \n    # --- ION-SURFACE INTERACTIONS ---\n    # Expand dimensions to compute all pairwise ion-atom distances\n    pos_exp = tf.expand_dims(positions, axis=1)  # (num_atoms, 1, 3)\n    ion_exp = tf.expand_dims(ion_positions, axis=0)  # (1, num_ions, 3)\n    r = tf.norm(pos_exp - ion_exp, axis=2)  # Shape: (num_atoms, num_ions)\n\n    # --- Gather interaction parameters ---\n    sigmas = tf.reshape(tf.gather(param_tensors['sigma_matrix'][ion_index], surface_indices),[-1,1])\n    epsilons = tf.reshape(tf.gather(param_tensors['epsilon_matrix'][ion_index], surface_indices),[-1,1])\n    cutoffs = tf.reshape(tf.gather(param_tensors['cutoff_matrix'][ion_index], surface_indices),[-1,1])\n\n    # Gather charges for surface atoms and the ion\n    q_surface = tf.reshape(tf.gather(param_tensors['q'], surface_indices),[-1,1])\n    q_ion = param_tensors['q'][ion_index]\n\n    # Calculate potential energy, applying a cutoff distance\n    atoms_energy_matrix = tf.where(r < cutoffs,\n                             physical_potential(r, epsilons, sigmas, q_ion, q_surface, param_tensors['k_e']),\n                             tf.zeros_like(r))\n\n    # Sum over surface atoms to get the total interaction energy for each ion\n    energy_per_ion = tf.reduce_sum(atoms_energy_matrix, axis=0)  # Shape: (num_ions,)\n\n    # --- ION-ION INTERACTIONS ---\n    diff_ion = tf.expand_dims(ion_positions, 0) - tf.expand_dims(ion_positions, 1)  # (num_ions, num_ions, 3)\n    r_ion = tf.norm(diff_ion, axis=-1)  # (num_ions, num_ions)\n\n    # Create a mask to exclude self-interactions (the diagonal)\n    eye = tf.eye(tf.shape(ion_positions)[0], dtype=tf.bool)\n    mask_offdiag = tf.logical_not(eye)\n\n    # Gather ion-ion interaction parameters\n    sigma_ion_ion = param_tensors['sigma_matrix'][ion_index, ion_index]\n    epsilon_ion_ion = param_tensors['epsilon_matrix'][ion_index, ion_index]\n    cutoff_ion_ion = param_tensors['cutoff_matrix'][ion_index, ion_index]\n\n    mask_cutoff = tf.less(r_ion, cutoff_ion_ion)\n    interaction_mask_ions = tf.logical_and(mask_offdiag, mask_cutoff)\n    \n    valid_r = tf.where(interaction_mask_ions, tf.maximum(r_ion, 1e-10), tf.ones_like(r_ion))\n    \n    ion_energy_matrix = tf.where(interaction_mask_ions,\n                                 physical_potential(valid_r, epsilon_ion_ion, sigma_ion_ion, q_ion, q_ion, param_tensors['k_e']),\n                                 tf.zeros_like(r_ion))\n    \n    ion_ion_energy_per_ion = tf.reduce_sum(ion_energy_matrix, axis=0)  # (num_ions,)\n    \n    # Calculate total energy\n    # Multiply by 0.5 to correct for double-counting in the pairwise sum\n    ion_ion_total_energy = tf.reduce_sum(ion_ion_energy_per_ion) * 0.5\n    energy_total_per_ion = energy_per_ion + ion_ion_energy_per_ion\n    energy_total = tf.reduce_sum(energy_per_ion) + ion_ion_total_energy\n\n    # --- PRI REGULARIZATION ---\n    epsilon_log = 1e-10  # For numerical stability in the log function\n\n    # Calculate information potentials\n    ip_ions = calculate_cross_information_potential(ion_positions, ion_positions, sigma_pri)\n    ip_surface = calculate_cross_information_potential(positions, positions, sigma_pri)\n    cip_ions_surface = calculate_cross_information_potential(ion_positions, positions, sigma_pri)\n    \n    # Calculate quadratic entropies (H2 = -log(V))\n    H2_ions = -tf.math.log(ip_ions + epsilon_log)\n    H2_surface = -tf.math.log(ip_surface + epsilon_log)\n    H2_cross = -tf.math.log(cip_ions_surface + epsilon_log)\n\n    # Calculate Cauchy-Schwarz Divergence\n    D_cs = 2 * H2_cross - H2_ions - H2_surface\n    # Calculate final PRI cost\n    pri_cost = (1 - lambda_pri) * H2_ions + 2 * lambda_pri * D_cs\n\n    # --- COMBINE AND RETURN ---\n    total_loss = energy_total + pri_weight * pri_cost\n    \n    return total_loss, energy_total_per_ion","metadata":{"id":"jr0V5MRhvaXp","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.315706Z","iopub.execute_input":"2025-10-09T01:59:32.315887Z","iopub.status.idle":"2025-10-09T01:59:32.334572Z","shell.execute_reply.started":"2025-10-09T01:59:32.315873Z","shell.execute_reply":"2025-10-09T01:59:32.334000Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Evaluation Metric: Purely physical energy of the final system state.**","metadata":{}},{"cell_type":"code","source":"@tf.function\ndef calculate_final_system_energy(positions, elements, ion_positions, ion_type, param_tensors):\n    \"\"\"\n    Calculates the final physical energy of the system without the PRI regularizer.\n    This function is used for evaluation after training is complete.\n    \"\"\"\n\n    # --- Gather parameters for each atom type ---\n    surface_indices = param_tensors['type_map'].lookup(elements)\n    ion_index = param_tensors['type_map'].lookup(tf.constant([ion_type]))[0]\n    \n    pos_exp = tf.expand_dims(positions, axis=1)\n    ion_exp = tf.expand_dims(ion_positions, axis=0)\n    r = tf.norm(pos_exp - ion_exp, axis=2)\n\n    # --- ION-SURFACE Interactions ---\n    sigmas = tf.reshape(tf.gather(param_tensors['sigma_matrix'][ion_index], surface_indices),[-1,1])\n    epsilons = tf.reshape(tf.gather(param_tensors['epsilon_matrix'][ion_index], surface_indices),[-1,1])\n    cutoffs = tf.reshape(tf.gather(param_tensors['cutoff_matrix'][ion_index], surface_indices),[-1,1])\n    q_surface = tf.reshape(tf.gather(param_tensors['q'], surface_indices),[-1,1])\n    q_ion = param_tensors['q'][ion_index]\n\n    atoms_energy_matrix = tf.where(r < cutoffs, physical_potential(r, epsilons, sigmas, q_ion, q_surface, param_tensors['k_e']),\n                             tf.zeros_like(r))\n    energy_per_ion = tf.reduce_sum(atoms_energy_matrix, axis=0)\n\n    # --- ION-ION INTERACTIONS ---\n    diff_ion = tf.expand_dims(ion_positions, 0) - tf.expand_dims(ion_positions, 1)\n    r_ion = tf.norm(diff_ion, axis=-1)\n    eye = tf.eye(tf.shape(ion_positions)[0], dtype=tf.bool)\n    mask_offdiag = tf.logical_not(eye)\n\n    sigma_ion_ion = param_tensors['sigma_matrix'][ion_index, ion_index]\n    epsilon_ion_ion = param_tensors['epsilon_matrix'][ion_index, ion_index]\n    cutoff_ion_ion = param_tensors['cutoff_matrix'][ion_index, ion_index]\n    \n    mask_cutoff = tf.less(r_ion, cutoff_ion_ion)\n    interaction_mask_ions = tf.logical_and(mask_offdiag, mask_cutoff)\n    valid_r = tf.where(interaction_mask_ions, tf.maximum(r_ion, 1e-10), tf.ones_like(r_ion))\n    \n    ion_energy_matrix = tf.where(interaction_mask_ions,\n                                 physical_potential(valid_r, epsilon_ion_ion, sigma_ion_ion, q_ion, q_ion, param_tensors['k_e']),\n                                 tf.zeros_like(r_ion))\n    ion_ion_energy_per_ion = tf.reduce_sum(ion_energy_matrix, axis=0)\n    \n    ion_ion_total_energy = tf.reduce_sum(ion_ion_energy_per_ion) * 0.5\n    physical_energy_total = tf.reduce_sum(energy_per_ion) + ion_ion_total_energy\n    \n    return physical_energy_total, energy_per_ion + ion_ion_energy_per_ion","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.335300Z","iopub.execute_input":"2025-10-09T01:59:32.335495Z","iopub.status.idle":"2025-10-09T01:59:32.350267Z","shell.execute_reply.started":"2025-10-09T01:59:32.335472Z","shell.execute_reply":"2025-10-09T01:59:32.349534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4. Training Utilities","metadata":{}},{"cell_type":"code","source":"# We define an scheduler to monitor the progress of the loss and adjust the LR acordingly \n\nclass DynamicLRSchedulerCallback:\n    \n    def __init__(self, optimizer, eta0, alpha, beta, total_epochs, verbose=\"high\"):\n        self.optimizer = optimizer\n        self.eta0 = eta0\n        self.alpha = alpha\n        self.beta = beta\n        self.total_epochs = total_epochs\n        self.verbose = verbose\n        \n    def on_epoch_end(self, epoch):\n        relative_progress = (epoch + 1) / self.total_epochs\n        scaling_factor = (1 + self.alpha * relative_progress)**(-self.beta)\n        eta = self.eta0*(scaling_factor)\n        self.optimizer.learning_rate.assign(eta)\n\n        if self.verbose == \"extreme\":\n            print(f'\\\\nEpoch {epoch + 1}: Loss reduced to {eta:.8f}.')\n        elif self.verbose == \"high\":\n            if (epoch + 1) % 25 == 0:\n                print(f'\\\\nEpoch {epoch + 1}: Loss reduced to {eta:.8f}.')\n        elif self.verbose == \"low\":\n            if (epoch+1) % 50 == 0:\n                print(f'\\\\nEpoch {epoch + 1}: Loss reduced to {eta:.8f}.')\n        else:\n            pass\n\n        ","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-10-09T01:59:32.351006Z","iopub.execute_input":"2025-10-09T01:59:32.351268Z","iopub.status.idle":"2025-10-09T01:59:32.367189Z","shell.execute_reply.started":"2025-10-09T01:59:32.351244Z","shell.execute_reply":"2025-10-09T01:59:32.366565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# We define an early stop callback to optimize convergence when possible\nclass EarlyStoppingCallback:\n    \"\"\"A simple callback class for implementing early stopping during training.\"\"\"\n    def __init__(self, patience, min_delta):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.wait = 0\n        self.best_loss = float('inf')\n        self.stopped_epoch = 0\n\n    def on_epoch_end(self, epoch, loss):\n        if loss < self.best_loss - self.min_delta:\n            self.best_loss = loss\n            self.wait = 0\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                self.stopped_epoch = epoch\n                return True  # Signal to stop training\n        return False  # Continue training","metadata":{"id":"LTjRNJ-wGl16","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.367930Z","iopub.execute_input":"2025-10-09T01:59:32.368411Z","iopub.status.idle":"2025-10-09T01:59:32.378103Z","shell.execute_reply.started":"2025-10-09T01:59:32.368394Z","shell.execute_reply":"2025-10-09T01:59:32.377460Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Bayesian Optimization Workflow","metadata":{}},{"cell_type":"markdown","source":"## 3.1. Objective Function for Optuna","metadata":{}},{"cell_type":"code","source":"def objective(trial, params, param_tensors):\n    \"\"\"\n    Objective function for Optuna to minimize.\n    It runs a condensed PIRIS simulation for a given set of hyperparameters\n    and returns the final physical energy.\n    \"\"\"\n    # Retrieve the initial position and k-means info from the study's user attributes\n    position_str = trial.study.user_attrs[\"starting_position\"]\n    configuracion = np.array(json.loads(position_str))\n    info = trial.study.user_attrs[\"info\"]\n    params = trial.study.user_attrs[\"params\"]\n    ion_type = params['ion_type'] \n    \n    # --- 1. Suggest hyperparameters from the trial object ---\n    # Initial distance factor relative to the characteristic length scale\n    factor_initial = trial.suggest_float(\"factor\", 1.0, 6.0)\n\n    # PRI hyperparameters\n    pri_weight_val = trial.suggest_float(\"pri_weight\", 0.0, 10.0)\n    lambda_pri_val = trial.suggest_float(\"lambda_pri\", 0.0, 1.0)\n    \n    # Sigma_pri search space is related to the system's length scale\n    sigma_pri_val = trial.suggest_float(\"sigma_pri\", 1.0* info[\"escala\"], 6 * info[\"escala\"])\n\n    # Fixed learning rate\n    eta0 = trial.suggest_float(\"learning_rate\", 1e-1, 1.1e-1, log=True)\n    # LR scheduler Hyper-hyperparameters\n    alpha = trial.suggest_int(\"alpha\", 5, 60) \n    beta = trial.suggest_float(\"beta\", 0.5, 1.5)\n\n    # --- 2. Setup the simulation for this trial ---\n    initial_ion_positions = build_ions(configuracion, factor_initial, info)\n    ion = tf.Variable(initial_ion_positions, dtype=tf.float32)\n\n    # Cast hyperparameters to TensorFlow constants\n    pri_weight = tf.constant(pri_weight_val, dtype=tf.float32)\n    lambda_pri = tf.constant(lambda_pri_val, dtype=tf.float32)\n    sigma_pri = tf.constant(sigma_pri_val, dtype=tf.float32)\n\n    # --- 3. Run a condensed training loop ---\n    epochs = 100  # Reduced for faster optimization trials\n    optimizer = tf.keras.optimizers.Adam(learning_rate=eta0)\n\n    lr_scheduler = DynamicLRSchedulerCallback(optimizer, eta0, alpha, beta, total_epochs=epochs, verbose=False) # Verbose is False for clean Optuna logs\n    \n    for epoch in range(epochs):\n        \n        with tf.GradientTape() as g:\n            g.watch(ion)\n            H_loss, _ = get_training_loss(sample_atoms, sample_elements, ion.value(), \n                                          pri_weight, lambda_pri, sigma_pri, \n                                          ion_type, param_tensors)\n        \n        grad_ = g.gradient(H_loss, ion)\n        grad_ = tf.clip_by_norm(grad_, 1.0)\n        \n        # Check for NaN gradients, which can occur with extreme hyperparameters\n        if tf.reduce_any(tf.math.is_nan(grad_)):\n            return 1e6 # Return a large value to penalize this trial\n\n        optimizer.apply_gradients(zip([grad_], [ion]))\n         # --- Call the scheduler at the end of the epoch to update Lr---\n        lr_scheduler.on_epoch_end(epoch)\n\n    # --- 4. Calculate and return the final physical energy ---\n    final_energy, _ = calculate_final_system_energy(sample_atoms, sample_elements, ion.value(),\n                                                    ion_type, param_tensors)\n    \n    return final_energy.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.381530Z","iopub.execute_input":"2025-10-09T01:59:32.382114Z","iopub.status.idle":"2025-10-09T01:59:32.392874Z","shell.execute_reply.started":"2025-10-09T01:59:32.382089Z","shell.execute_reply":"2025-10-09T01:59:32.392182Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.2. Main Optimization Loop","metadata":{}},{"cell_type":"code","source":"def optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=42):\n    \"\"\"\n    Executes the main hyperparameter optimization loop.\n\n    Args:\n        positions (np.ndarray): The adsorbent surface positions.\n        geometria (str): The geometry type ('planar' or '3D').\n        puntos_por_eje (int): Number of candidate points to generate per axis/dimension.\n        k (int): Number of initial configurations to test with Optuna.\n        num_ni (int): Number of ions to adsorb simultaneously.\n        num_trials (int): Number of optimization trials to run for each initial configuration.\n        params (dict): Dictionary of simulation parameters.\n        param_tensors (dict): Dictionary of TensorFlow tensor parameters.\n\n    Returns:\n        tuple: A tuple containing:\n            - list: A list of all completed Optuna study objects.\n            - list: A list of the best trial from each study.\n    \"\"\"\n    # Define the bounding box around the surface for candidate points\n    info_k_means = calcular_limites_superficie(positions, geometria, params=params, param_tensors=param_tensors, padding=2.0)\n    \n    # Create the grid of candidate points\n    malla = starting_point_suggestions(info_k_means, puntos_por_eje)\n    \n    # Select diverse starting configurations using k-means++\n    configuraciones = generate_xy(malla, k, num_ni, random_seed)\n    \n    Studies = [] # To store complete study objects\n    Trials = [] # To store the best trial from each study\n    \n    for i, xy_positions in enumerate(tqdm(configuraciones, desc=\"Hyperparameter optimization\")):\n        print(f\"Optimizing for starting configuration {i+1}/{k}...\")\n        study_name = f'Starting_position_{i}'\n        # Create an Optuna study object with a Gaussian Process sampler\n        study = optuna.create_study(study_name=study_name, direction='minimize', sampler=GPSampler(seed=10))\n        \n        # Store necessary info as user attributes in the study object\n        list_positions = xy_positions.tolist()\n        study.set_user_attr(\"starting_position\", json.dumps(list_positions))\n        study.set_user_attr(\"info\", info_k_means)\n        study.set_user_attr(\"params\", params)\n        \n        # Pass parameters to the objective function using a lambda\n        objective_with_params = lambda trial: objective(trial, params, param_tensors)\n\n        # Run the optimization\n        study.optimize(objective_with_params, n_trials=num_trials)\n        \n        # --- Store results ---\n        Studies.append(study)\n        Trials.append(study.best_trial)\n        \n    return Studies, Trials","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.393577Z","iopub.execute_input":"2025-10-09T01:59:32.393752Z","iopub.status.idle":"2025-10-09T01:59:32.407966Z","shell.execute_reply.started":"2025-10-09T01:59:32.393738Z","shell.execute_reply":"2025-10-09T01:59:32.407374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def optimization_summary(Trials):\n    \"\"\"\n    Generates and prints a summary DataFrame of the best trials from the optimization.\n\n    Args:\n        Trials (list): A list of the best trial objects from each study.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the hyperparameters and results of each best trial.\n    \"\"\"\n    records = []\n    for trial in Trials:\n        record = {\"Energy\": trial.value}\n        record.update(trial.params)\n        records.append(record)\n    data = pd.DataFrame(records)\n    print(\"\\nSummary of the best trials across all starting configurations:\")\n    print(data.describe())\n    return data","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.408672Z","iopub.execute_input":"2025-10-09T01:59:32.408827Z","iopub.status.idle":"2025-10-09T01:59:32.420766Z","shell.execute_reply.started":"2025-10-09T01:59:32.408814Z","shell.execute_reply":"2025-10-09T01:59:32.420094Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.3. Optimization Results Visualization","metadata":{}},{"cell_type":"markdown","source":"**Hyperparameter Importance Plot**","metadata":{}},{"cell_type":"code","source":"def importance_plot(Studies):\n    \"\"\"\n    Generates and saves a plot showing the mean importance and standard deviation\n    of each hyperparameter across all optimization studies.\n\n    Args:\n        Studies (list): A list of all completed Optuna study objects.\n    \"\"\"\n    if PLOTTING_DISABLED:\n        return\n        \n    try:\n        # Get parameter importances from all studies\n        all_importances = [optuna.importance.get_param_importances(s) for s in Studies]\n        \n        # Convert to a DataFrame for easy aggregation\n        df_importances = pd.DataFrame(all_importances).fillna(0)\n        \n        # Calculate mean and standard deviation for each hyperparameter\n        mean_importances = df_importances.mean().sort_values(ascending=False)\n        std_importances = df_importances.std().loc[mean_importances.index]\n        \n        # Create the plot\n        plt.figure(figsize=(12, 8))\n        plt.barh(\n            y=mean_importances.index,\n            width=mean_importances,\n            xerr=std_importances,\n            capsize=5,\n            color=sns.color_palette(\"viridis_r\", len(mean_importances))\n        )\n        \n        plt.gca().invert_yaxis() # Display most important parameter at the top\n        plt.title('Mean Hyperparameter Importance Across All Initial Positions', fontsize=16, fontweight='bold')\n        plt.ylabel('Hyperparameters', fontsize=12)\n        plt.xlabel('Mean Importance', fontsize=12)\n        plt.tight_layout()\n        \n        # Save the figure\n        plot_name = f\"Parameter_importance_{sample_name}.pdf\"\n        filePath = os.path.join(output_dir, plot_name)\n        plt.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\n        plt.show()\n        \n    except RuntimeError as e:\n        if \"zero total variance\" in str(e):\n            print(\"\\n--- SKIPPING IMPORTANCE PLOT ---\")\n            print(\"Reason: Could not be generated because all trials resulted in the same value.\")\n            print(\"This may indicate an issue with the optimization objective or search space.\")\n        else:\n            raise e","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.421598Z","iopub.execute_input":"2025-10-09T01:59:32.421833Z","iopub.status.idle":"2025-10-09T01:59:32.433115Z","shell.execute_reply.started":"2025-10-09T01:59:32.421812Z","shell.execute_reply":"2025-10-09T01:59:32.432540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Contour Plots**","metadata":{}},{"cell_type":"code","source":"def contour_plot(Trials, Studies):\n    \"\"\"\n    Identifies the best overall study and generates contour plots for its most important hyperparameters.\n\n    Args:\n        Trials (list): A list of the best trial from each study.\n        Studies (list): A list of all completed Optuna study objects.\n\n    Returns:\n        optuna.study.Study: The study object corresponding to the best overall trial.\n    \"\"\"\n    # Find the best trial among all studies\n    best_overall_trial = min(Trials, key=lambda t: t.value)\n    \n    # Find the parent study object for that trial\n    best_study = None\n    for study in Studies:\n        if study.best_trial == best_overall_trial:\n            best_study = study\n            break\n    \n    if best_study is None:\n        raise RuntimeError(\"Could not find the parent study for the best trial.\")\n\n    # If plotting is disabled, we still need to return the best_study for the final training\n    if PLOTTING_DISABLED:\n        return best_study\n        \n    # Generate, display, and save contour plots\n    z_sigma_plot = plot_contour(best_study, params=[\"factor\", \"sigma_pri\"])\n    z_sigma_plot.update_layout(title=\"Contour Plot: Initial Distance Factor vs. Sigma_PRI\")\n    z_sigma_plot.show()\n    plot_name_sigma = f'z_sigma_plot_{sample_name}.pdf'\n    filePath = os.path.join(output_dir, plot_name_sigma)\n    z_sigma_plot.write_image(filePath)\n    \n    pri_physics_plot = plot_contour(best_study, params=[\"pri_weight\", \"lambda_pri\"])\n    pri_physics_plot.update_layout(title=\"Contour Plot: PRI Weight vs. Lambda_PRI\")\n    pri_physics_plot.show()\n    plot_name = f'pri_physics_plot_{sample_name}.pdf'\n    filePath = os.path.join(output_dir, plot_name)\n    pri_physics_plot.write_image(filePath)\n    \n    return best_study","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.433770Z","iopub.execute_input":"2025-10-09T01:59:32.433952Z","iopub.status.idle":"2025-10-09T01:59:32.450405Z","shell.execute_reply.started":"2025-10-09T01:59:32.433938Z","shell.execute_reply":"2025-10-09T01:59:32.449693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Wrapper function to display all optimization results.**","metadata":{}},{"cell_type":"code","source":"def optimization_results(Studies, Trials):\n    \"\"\"\n    Calls all visualization and summary functions for the optimization results.\n\n    Args:\n        Studies (list): A list of all completed Optuna study objects.\n        Trials (list): A list of the best trial from each study.\n\n    Returns:\n        optuna.study.Study: The study object corresponding to the best overall trial.\n    \"\"\"\n    optimization_summary(Trials)\n    importance_plot(Studies)\n    best_study = contour_plot(Trials, Studies)\n    return best_study","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.451111Z","iopub.execute_input":"2025-10-09T01:59:32.451335Z","iopub.status.idle":"2025-10-09T01:59:32.463658Z","shell.execute_reply.started":"2025-10-09T01:59:32.451315Z","shell.execute_reply":"2025-10-09T01:59:32.462876Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Final Model Training","metadata":{}},{"cell_type":"markdown","source":"**This loop uses the best hyperparameters found by Optuna to run a full training process.**","metadata":{}},{"cell_type":"code","source":"def training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, params, param_tensors):\n    \"\"\"\n    Runs the final, full training loop using the optimal hyperparameters found.\n\n    Args:\n        best_study (optuna.study.Study): The best study object from the optimization phase.\n        epochs (int): The number of epochs for the final training.\n        positions (np.ndarray): Surface coordinates for plotting.\n        sample_atoms (tf.Tensor): Surface coordinates for training.\n        sample_elements (tf.Tensor): Surface element types for training.\n\n    Returns:\n        tuple: A tuple containing the final ion positions (tf.Variable and np.ndarray),\n               the starting positions (np.ndarray), the loss history (list), and the final gradient.\n    \"\"\"\n    # Extract the best starting configuration and hyperparameters from the study\n    best_starting_position_str = best_study.user_attrs[\"starting_position\"]\n    best_starting_position_list = json.loads(best_starting_position_str)\n    best_starting_position = np.array(best_starting_position_list)\n    best_params = best_study.best_trial.params\n    \n    final_ion_type = params['ion_type']\n    \n    print(\"\\n--- Starting Final Training with Best Hyperparameters ---\")\n    for key, value in best_params.items():\n        print(f\"  - {key}: {value:.4f}\")\n    \n    final_info = best_study.user_attrs[\"info\"]\n    \n    # Set up the final simulation using these optimal parameters\n    final_factor = best_params['factor']\n    final_pri_weight = tf.constant(best_params['pri_weight'], dtype=tf.float32)\n    final_lambda_pri = tf.constant(best_params['lambda_pri'], dtype=tf.float32)\n    final_sigma_pri = tf.constant(best_params['sigma_pri'], dtype=tf.float32)\n    final_lr = best_params['learning_rate']\n    final_alpha = best_params['alpha']\n    final_beta = best_params['beta']\n    \n    # Re-initialize the ion at the optimal starting position and height\n    final_initial_positions = build_ions(best_starting_position, final_factor, final_info)\n    ion_final = tf.Variable(final_initial_positions, dtype=tf.float32)\n    ion_final_ = ion_final.numpy().copy()\n    optimizer_final = tf.keras.optimizers.Adam(learning_rate=final_lr)\n\n    if not PLOTTING_DISABLED:\n        # Plot the initial state of the system\n        initial_state = plt.figure(figsize=(8, 7))\n        ax = initial_state.add_subplot(111, projection='3d')\n        ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], c='b', s=20, label='Surface Atoms')\n        ax.scatter(ion_final_[:, 0], ion_final_[:, 1], ion_final_[:, 2], c='r', s=40, marker='x', label='Initial Ion Position')\n        ax.set_xlabel('X (Å)')\n        ax.set_ylabel('Y (Å)')\n        ax.set_zlabel('Z (Å)')\n        ax.set_title('System Initial State')\n        ax.legend()\n        plot_name = f'initial_state_{sample_name}.pdf'\n        filePath = os.path.join(output_dir, plot_name)\n        initial_state.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\n        initial_state.show()\n    \n    # Final training loop\n    starting_pos = ion_final_.copy()\n    loss_history = []\n    lr_scheduler_final = DynamicLRSchedulerCallback(optimizer_final, final_lr, final_alpha, final_beta, total_epochs=epochs, verbose=\"low\")\n    early_stopping = EarlyStoppingCallback(patience=25, min_delta=0.0000001)\n    epoch_bar = tqdm(range(epochs), desc=\"Final Training Progress\")\n    for epoch in epoch_bar:\n        epoch_bar.set_description(f\"Epoch {epoch+1}/{epochs}\")\n        \n        with tf.GradientTape() as g:\n            g.watch(ion_final)\n            H_loss, ion_total_energies_ = get_training_loss(sample_atoms, sample_elements, ion_final.value(),\n                                          final_pri_weight, final_lambda_pri, final_sigma_pri,\n                                          final_ion_type, param_tensors)\n            loss_history.append(H_loss)\n        grad_ = g.gradient(H_loss, ion_final)\n        grad_ = tf.clip_by_norm(grad_, 1.0)\n        optimizer_final.apply_gradients(zip([grad_], [ion_final]))\n\n        lr_scheduler_final.on_epoch_end(epoch)\n        current_lr = optimizer_final.learning_rate.numpy()\n        \n        if (epoch + 1) % 25 == 0:\n            epoch_bar.set_postfix(loss=f\"{H_loss.numpy():.4f}\", lr=f\"{current_lr:.6f}\")\n\n        ion_final_ = ion_final.numpy()\n        gradN_3D = -10 * current_lr * grad_.numpy() # Store  gradient for visualization\n\n        if epoch == epochs//2 and not PLOTTING_DISABLED: #Plot a mid-training state only if plots are enabled\n        \n        \n            mid_state = plt.figure(figsize=(6, 6))\n            ax = mid_state.add_subplot(111, projection='3d')\n        \n            ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], c='b', s=20, label='positions')\n            ax.scatter(ion_final_[:, 0], ion_final_[:, 1], ion_final_[:, 2], c='r', s=40, marker='x', label='ion_')\n        \n            ax.quiver(ion_final_[:, 0], ion_final_[:, 1], ion_final_[:, 2], gradN_3D[:, 0], gradN_3D[:, 1], gradN_3D[:, 2],\n                      color='g', length=0.5, normalize=True, label='Gradient Vectors')  # Adjust length and normalize as needed\n        \n        \n            ax.set_xlabel('X')\n            ax.set_ylabel('Y')\n            ax.set_zlabel('Z')\n            ax.legend()\n\n            plot_name = f'mid_state_{sample_name}.pdf'\n            filePath = os.path.join(output_dir, plot_name)\n            mid_state.savefig(\n            filePath,\n            format='pdf',\n            bbox_inches='tight', \n            dpi=300             \n            )\n            mid_state.show()\n            \n        # Call the callback's on_epoch_end method\n        \"\"\"if early_stopping.on_epoch_end(epoch, H_loss.numpy()):\n            print(f'Early stopping at epoch {early_stopping.stopped_epoch + 1}')\n            break\"\"\"\n                \n    return ion_final, ion_final_,starting_pos, loss_history, gradN_3D","metadata":{"id":"bEucgi8zouu6","trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.464386Z","iopub.execute_input":"2025-10-09T01:59:32.464612Z","iopub.status.idle":"2025-10-09T01:59:32.482464Z","shell.execute_reply.started":"2025-10-09T01:59:32.464596Z","shell.execute_reply":"2025-10-09T01:59:32.481773Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Final Evaluation and Results","metadata":{}},{"cell_type":"code","source":"def test_step(sample_atoms, sample_elements, ion_final, ion_type, param_tensors):\n    \"\"\"Calculates the final physical energy of the system for evaluation.\"\"\"\n    final_energy, final_energy_per_ion = calculate_final_system_energy(\n        sample_atoms,\n        sample_elements,\n        ion_final.value(),\n        ion_type,\n        param_tensors\n    )\n        \n    # Convert to NumPy for reporting\n    system_energy = final_energy.numpy()\n    final_energy_per_ion = final_energy_per_ion.numpy()\n    return system_energy, final_energy_per_ion","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.483089Z","iopub.execute_input":"2025-10-09T01:59:32.483328Z","iopub.status.idle":"2025-10-09T01:59:32.496559Z","shell.execute_reply.started":"2025-10-09T01:59:32.483300Z","shell.execute_reply":"2025-10-09T01:59:32.495942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_results(num_atoms, num_ni, system_energy, final_energy_per_ion, starting_pos, ion_final_):\n    \"\"\"\n    Displays a summary of the final energy results of the simulation.\n\n    Args:\n        num_atoms (int): Number of atoms in the adsorbent surface.\n        num_ni (int): Number of adsorbed ions.\n        system_energy (float): Total final energy of the system.\n        final_energy_per_ion (np.ndarray): Final energy of each individual ion.\n        starting_pos (np.ndarray): Initial positions of the ions.\n        ion_final_ (np.ndarray): Final positions of the ions.\n    \"\"\"\n    print(f'\\n--- Final System Results ---')\n    print(f'Surface Atoms: {num_atoms} | Adsorbed Ions: {num_ni}')\n    print(f'Total System Energy: {system_energy:.5f} eV')\n    print(f'Average Adsorption Energy per Ion: {system_energy/num_ni:.5f} eV/ion')\n    print(f\"Standard Deviation of Ion Energy: {np.std(final_energy_per_ion):.5f} eV\")\n    \n    distance = ion_final_ - starting_pos\n    mean_vector = np.mean(distance, axis=0)\n    mean_magnitude = np.mean(np.linalg.norm(distance, axis=1))\n    print(f'Mean Displacement Vector: {mean_vector}')\n    print(f'Mean Displacement Magnitude: {mean_magnitude:.3f} Å')\n    print(f'--------------------------\\n')","metadata":{"id":"a0Nx9f41dRvc","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.497294Z","iopub.execute_input":"2025-10-09T01:59:32.497519Z","iopub.status.idle":"2025-10-09T01:59:32.506599Z","shell.execute_reply.started":"2025-10-09T01:59:32.497503Z","shell.execute_reply":"2025-10-09T01:59:32.505917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_results(loss_history, elements, positions, starting_pos, ion_final_, num_ni, gradN_3D, params):\n    \"\"\"\n    Generates and saves the final summary plots for the simulation run.\n    \"\"\"\n    if PLOTTING_DISABLED:\n        return \n        \n    # --- Loss evolution plot ---\n    plt.figure(figsize=(10, 5))\n    plt.plot(loss_history)\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Total Loss (Physical + PRI)\")\n    plt.title(\"Loss Evolution During Final Training\")\n    plt.grid(True)\n    plot_name = f'loss_evolution_{sample_name}.pdf'\n    filePath = os.path.join(output_dir, plot_name)\n    plt.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\n    plt.show()\n\n    # --- 3D plot of initial and final positions ---\n    final_state = plt.figure(figsize=(12, 10))\n    ax = final_state.add_subplot(111, projection='3d')\n    \n    ion_type = params['ion_type']\n    surface_atom_types = np.unique(elements)\n    \n    palette = sns.color_palette(\"viridis_r\", len(surface_atom_types))\n    colors_map = {atom_type: color for atom_type, color in zip(surface_atom_types, palette)}\n\n    # Plot surface atoms\n    for atom_type in surface_atom_types:\n        idx = (elements == atom_type)\n        ax.scatter(positions[idx, 0], positions[idx, 1], positions[idx, 2],\n                   color=colors_map.get(atom_type, \"black\"),\n                   label=f'Surface ({atom_type})', s=80, alpha=0.6)\n    \n    # Plot ion positions\n    ax.scatter(starting_pos[:, 0], starting_pos[:, 1], starting_pos[:, 2],\n               color='orange', label='Ions (Initial)', s=150, marker='x')\n    ax.scatter(ion_final_[:, 0], ion_final_[:, 1], ion_final_[:, 2],\n               color='red', label='Ions (Final)', s=150, edgecolors='k')\n    \n    # Plot arrows indicating the path from initial to final positions\n    for i in range(num_ni):\n        ax.quiver(starting_pos[i, 0], starting_pos[i, 1], starting_pos[i, 2],\n                  ion_final_[i, 0] - starting_pos[i, 0],\n                  ion_final_[i, 1] - starting_pos[i, 1],\n                  ion_final_[i, 2] - starting_pos[i, 2],\n                  color='green', arrow_length_ratio=0.3, alpha=0.7, label='Displacement' if i == 0 else \"\")\n    \n    ax.set_xlabel(\"X (Å)\")\n    ax.set_ylabel(\"Y (Å)\")\n    ax.set_zlabel(\"Z (Å)\")\n    ax.set_title(f\"Initial and Final Ion Positions for {sample_name}\")\n    ax.legend()\n    final_state.tight_layout()\n    plot_name = f'final_state_{sample_name}.pdf'\n    filePath = os.path.join(output_dir, plot_name)\n    final_state.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\n    final_state.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.507404Z","iopub.execute_input":"2025-10-09T01:59:32.507626Z","iopub.status.idle":"2025-10-09T01:59:32.522745Z","shell.execute_reply.started":"2025-10-09T01:59:32.507612Z","shell.execute_reply":"2025-10-09T01:59:32.522101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D, params, param_tensors):\n    \"\"\"Wrapper function to call all final evaluation and result reporting functions.\"\"\"\n    ion_type = params['ion_type']\n    system_energy, final_energy_per_ion = test_step(sample_atoms, sample_elements, ion_final, ion_type, param_tensors)\n    show_results(num_atoms, num_ni, system_energy, final_energy_per_ion, starting_pos, ion_final_)\n    plot_results(loss_history, elements, positions, starting_pos, ion_final_, num_ni, gradN_3D, params)\n\n    return system_energy","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.523529Z","iopub.execute_input":"2025-10-09T01:59:32.523768Z","iopub.status.idle":"2025-10-09T01:59:32.536194Z","shell.execute_reply.started":"2025-10-09T01:59:32.523753Z","shell.execute_reply":"2025-10-09T01:59:32.535496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Simulation Runs\n**This section executes the full pipeline for different sample structures.**","metadata":{}},{"cell_type":"code","source":"# General simulation parameters\nk = 20 # Number of initial configurations to test in the optimization phase\nnum_trials = 50 # Number of Optuna trials per configuration\nepochs = 300 # Number of epochs for the final training run","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.536939Z","iopub.execute_input":"2025-10-09T01:59:32.537406Z","iopub.status.idle":"2025-10-09T01:59:32.547659Z","shell.execute_reply.started":"2025-10-09T01:59:32.537384Z","shell.execute_reply":"2025-10-09T01:59:32.547102Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.1. Sample 1: Graphene-like ZnO Sheet","metadata":{}},{"cell_type":"code","source":"# Parameters for creating this sample\na_zno = 1.863  # Zn-O bond length (Å)\nbeta_zno = 30 * np.pi / 180 # Hexagon projection angle (radians)\ndist_x = 2 * a_zno * np.cos(beta_zno)\ndist_y = a_zno * np.sin(beta_zno)\noffset_x = dist_x / 2\ncols = 6\nrows = 6","metadata":{"id":"phxfC95mS7gy","trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.548409Z","iopub.execute_input":"2025-10-09T01:59:32.548601Z","iopub.status.idle":"2025-10-09T01:59:32.559212Z","shell.execute_reply.started":"2025-10-09T01:59:32.548587Z","shell.execute_reply":"2025-10-09T01:59:32.558429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Simulation parameter dictionary for this sample ---\n\n# Physical constants\nkj_mol_to_ev = 0.01034 # Conversion factor from kJ/mol to eV/atom\nk_e = 14.3996 # Coulomb's constant in (eV * Å / e^2)\n\n# Master dictionary containing all simulation parameters\nparams = {\n    'atom_types': [\"Zn\", \"O\", \"Ni\"], # Defines the order for parameter matrices\n    'ion_type': 'Ni', # Specifies which atom type is the adsorbing ion\n\n    # Per-atom parameters: sigma (van der Waals radius, Å), epsilon (potential well depth, eV), q (partial charge, e)\n    'atom_params': {\n        'Zn': {\"sigma\": 4.045, \"epsilon\": 0.23 * kj_mol_to_ev, \"q\": 0.86},\n        'O': {\"sigma\": 3.71, \"epsilon\": 1.736 * kj_mol_to_ev, \"q\": -0.86},\n        'Ni': {\"sigma\": 2.834, \"epsilon\": 0.0628 * kj_mol_to_ev, \"q\": 2}\n    },\n    \n    'coulomb_constant': k_e\n}\n\n# --- Build cross-interaction parameter matrices using Lorentz-Berthelot mixing rules ---\nnum_types = len(params['atom_types'])\natom_types = params['atom_types']\n\nsigma_matrix = [[0.0] * num_types for _ in range(num_types)]\nepsilon_matrix = [[0.0] * num_types for _ in range(num_types)]\ncutoff_matrix = [[0.0] * num_types for _ in range(num_types)]\n\nfor i in range(num_types):\n    for j in range(num_types):\n        type1, type2 = atom_types[i], atom_types[j]\n        sigma1, epsilon1 = params['atom_params'][type1]['sigma'], params['atom_params'][type1]['epsilon']\n        sigma2, epsilon2 = params['atom_params'][type2]['sigma'], params['atom_params'][type2]['epsilon']\n        \n        # Lorentz-Berthelot mixing rules\n        mixed_sigma = (sigma1 + sigma2) / 2.0\n        mixed_epsilon = (epsilon1 * epsilon2)**0.5\n        \n        sigma_matrix[i][j] = mixed_sigma\n        epsilon_matrix[i][j] = mixed_epsilon\n        cutoff_matrix[i][j] = 2.5 * mixed_sigma # Cutoff is typically 2.5 * sigma\n\n# Convert parameters to TensorFlow tensors for use in decorated functions\nparam_tensors = {\n    'type_map': tf.lookup.StaticHashTable(\n        initializer=tf.lookup.KeyValueTensorInitializer(\n            keys=tf.constant(atom_types, dtype=tf.string),\n            values=tf.constant(list(range(num_types)), dtype=tf.int32)\n        ),\n        default_value=tf.constant(-1, dtype=tf.int32)\n    ),\n    'q': tf.constant([params['atom_params'][t]['q'] for t in atom_types], dtype=tf.float32),\n    'sigma_matrix': tf.constant(sigma_matrix, dtype=tf.float32),\n    'epsilon_matrix': tf.constant(epsilon_matrix, dtype=tf.float32),\n    'cutoff_matrix': tf.constant(cutoff_matrix, dtype=tf.float32),\n    'k_e': tf.constant(params['coulomb_constant'], dtype=tf.float32)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:32.560005Z","iopub.execute_input":"2025-10-09T01:59:32.560290Z","iopub.status.idle":"2025-10-09T01:59:33.445651Z","shell.execute_reply.started":"2025-10-09T01:59:32.560275Z","shell.execute_reply":"2025-10-09T01:59:33.444838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Sample construction function ---\n\ndef muestra_ZnO_grafeno(rows, a, dist_y, offset_x, cols, dist_x):\n    \"\"\"\n    Generates a graphene-like ZnO sheet structure.\n\n    Returns:\n        tuple: A tuple containing num_atoms, positions, elements, sample_atoms, sample_elements, and geometry type.\n    \"\"\"\n    coord_dict = {\"Zn\": [], \"O\": []}\n    geometria = \"planar\"\n    for row in range(rows):\n        y_zn = row * (a + dist_y)\n        y_o = y_zn + a\n        x_offset = offset_x if row % 2 == 1 else 0\n    \n        for col in range(cols):\n            x = col * dist_x + x_offset\n            coord_dict[\"Zn\"].append((x, y_zn, 0))\n            coord_dict[\"O\"].append((x, y_o, 0))\n    \n    positions, elements = [], []\n    for atom_type, coords in coord_dict.items():\n        for pos in coords:\n            positions.append(pos)\n            elements.append(atom_type)\n    \n    num_atoms = len(positions)\n    positions = np.array(positions)\n    elements = np.array(elements)\n    # TensorFlow data\n    sample_atoms = tf.convert_to_tensor(positions, dtype=tf.float32)\n    sample_elements = tf.convert_to_tensor(elements, dtype=tf.string)\n\n    if PLOTTING_DISABLED:\n        return num_atoms, positions, elements, sample_atoms, sample_elements, geometria\n    \n    colors = {\"Zn\": \"blue\", \"O\": \"grey\"}\n    fig = plt.figure(figsize=(7, 6))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    for atom_type in set(elements):\n        idx = [i for i, e in enumerate(elements) if e == atom_type]\n        pos = positions[idx]\n        ax.scatter(pos[:, 0], pos[:, 1], pos[:, 2],\n                   color=colors.get(atom_type, \"black\"),\n                   label=atom_type, s=100, edgecolors='k')\n    \n    ax.set_xlabel(\"X (Å)\")\n    ax.set_ylabel(\"Y (Å)\")\n    ax.set_zlabel(\"Z (Å)\")\n    ax.set_title(\"Graphene-like ZnO Structure\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n    \n    return num_atoms, positions, elements, sample_atoms, sample_elements, geometria","metadata":{"id":"PM1vm4bXLohs","trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.446372Z","iopub.execute_input":"2025-10-09T01:59:33.446625Z","iopub.status.idle":"2025-10-09T01:59:33.455080Z","shell.execute_reply.started":"2025-10-09T01:59:33.446599Z","shell.execute_reply":"2025-10-09T01:59:33.454314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Execute the full pipeline for Sample 1 and time it\nstart_time = time.time()\nsample_name = \"ZnO_Graphene\"\n\nnum_atoms, positions, elements, sample_atoms, sample_elements, geometria = muestra_ZnO_grafeno(rows,a_zno,dist_y,offset_x,cols,dist_x)\npuntos_por_eje = 50\nnum_ni = 1\n\nStudies, Trials = optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=42)\nbest_study = optimization_results(Studies, Trials)\nion_final, ion_final_, starting_pos, loss_history, gradN_3D = training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, \n                                                                            params, param_tensors)\n_ = test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D,\n                params, param_tensors)\n\nend_time = time.time()\nexc_time = end_time - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.455740Z","iopub.execute_input":"2025-10-09T01:59:33.455928Z","iopub.status.idle":"2025-10-09T01:59:33.468424Z","shell.execute_reply.started":"2025-10-09T01:59:33.455913Z","shell.execute_reply":"2025-10-09T01:59:33.467693Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total execution time for this sample: {exc_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.469291Z","iopub.execute_input":"2025-10-09T01:59:33.469530Z","iopub.status.idle":"2025-10-09T01:59:33.481849Z","shell.execute_reply.started":"2025-10-09T01:59:33.469510Z","shell.execute_reply":"2025-10-09T01:59:33.481169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.2. Sample 2: Spherical Aluminum Nanoparticle (FCC)","metadata":{}},{"cell_type":"code","source":"# Parameters for creating this sample\nceldas_largo = 10\nceldas_alto = 10\nceldas_profundidad = 10\na = 7.9 # Lattice parameter (Å)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.482679Z","iopub.execute_input":"2025-10-09T01:59:33.482932Z","iopub.status.idle":"2025-10-09T01:59:33.493505Z","shell.execute_reply.started":"2025-10-09T01:59:33.482908Z","shell.execute_reply":"2025-10-09T01:59:33.492888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Simulation parameter dictionary for this sample ---\nkj_mol_to_ev = 0.01034\nk_e = 14.3996\n\nparams = {\n    'atom_types': [\"Al\", \"Hg\"],\n    'ion_type': 'Hg',\n    'atom_params': {\n        'Al': {\"sigma\": 3.302, \"epsilon\": 7.700e-6 * kj_mol_to_ev, \"q\": 1.575},\n        'Hg': {\"sigma\": 2.790, \"epsilon\": 10.031 * kj_mol_to_ev, \"q\": 2}\n    },\n    'coulomb_constant': k_e\n}\n\n# --- Build cross-interaction parameter matrices ---\nnum_types = len(params['atom_types'])\natom_types = params['atom_types']\nsigma_matrix = [[0.0] * num_types for _ in range(num_types)]\nepsilon_matrix = [[0.0] * num_types for _ in range(num_types)]\ncutoff_matrix = [[0.0] * num_types for _ in range(num_types)]\n\nfor i in range(num_types):\n    for j in range(num_types):\n        type1, type2 = atom_types[i], atom_types[j]\n        sigma1, epsilon1 = params['atom_params'][type1]['sigma'], params['atom_params'][type1]['epsilon']\n        sigma2, epsilon2 = params['atom_params'][type2]['sigma'], params['atom_params'][type2]['epsilon']\n        mixed_sigma = (sigma1 + sigma2) / 2.0\n        mixed_epsilon = (epsilon1 * epsilon2)**0.5\n        sigma_matrix[i][j] = mixed_sigma\n        epsilon_matrix[i][j] = mixed_epsilon\n        cutoff_matrix[i][j] = 2.5 * mixed_sigma\n\n# --- Convert to TensorFlow tensors ---\nparam_tensors = {\n    'type_map': tf.lookup.StaticHashTable(\n        initializer=tf.lookup.KeyValueTensorInitializer(keys=tf.constant(atom_types, dtype=tf.string), values=tf.constant(list(range(num_types)), dtype=tf.int32)),\n        default_value=tf.constant(-1, dtype=tf.int32)\n    ),\n    'q': tf.constant([params['atom_params'][t]['q'] for t in atom_types], dtype=tf.float32),\n    'sigma_matrix': tf.constant(sigma_matrix, dtype=tf.float32),\n    'epsilon_matrix': tf.constant(epsilon_matrix, dtype=tf.float32),\n    'cutoff_matrix': tf.constant(cutoff_matrix, dtype=tf.float32),\n    'k_e': tf.constant(params['coulomb_constant'], dtype=tf.float32)\n}","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.494341Z","iopub.execute_input":"2025-10-09T01:59:33.494579Z","iopub.status.idle":"2025-10-09T01:59:33.510942Z","shell.execute_reply.started":"2025-10-09T01:59:33.494556Z","shell.execute_reply":"2025-10-09T01:59:33.510221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Sample building function ---\n\ndef muestra_Al_dummy(celdas_largo, celdas_alto, celdas_profundidad, a):\n    \"\"\"\n    Generates a spherical Aluminum (Al) nanoparticle with an FCC structure.\n    The sphere is carved out of a larger cubic supercell.\n    \"\"\"\n    element = \"Al\"\n    geometria = \"3D\"\n    \n    # Relative positions of atoms within a single FCC unit cell\n    relativas_fcc = np.array([\n        [0.0, 0.0, 0.0], [0.5, 0.5, 0.0],\n        [0.5, 0.0, 0.5], [0.0, 0.5, 0.5]\n    ])\n\n    # Vectorized generation of the cubic supercell\n    i, j, k = np.arange(celdas_largo), np.arange(celdas_alto), np.arange(celdas_profundidad)\n    celdas_origenes = np.vstack(np.meshgrid(i, j, k)).reshape(3, -1).T\n    full_lattice_relative = celdas_origenes[:, np.newaxis, :] + relativas_fcc\n    full_lattice_positions = full_lattice_relative.reshape(-1, 3) * a\n    \n    # Carve a sphere from the center of the supercell\n    centro = np.array([celdas_largo, celdas_alto, celdas_profundidad]) * a / 2\n    radio_esfera = min(celdas_largo, celdas_alto, celdas_profundidad) * a / 2.0\n    distancias_al_centro = np.linalg.norm(full_lattice_positions - centro, axis=1)\n    mascara_esfera = distancias_al_centro <= radio_esfera\n    positions = full_lattice_positions[mascara_esfera]\n\n    # Prepare output variables\n    num_atoms = len(positions)\n    if num_atoms == 0:\n        print(\"Warning: No atoms were generated. Cell size or radius may be too small.\")\n    \n    elements = np.full(num_atoms, element)\n    sample_atoms = tf.convert_to_tensor(positions, dtype=tf.float32)\n    sample_elements = tf.convert_to_tensor(elements, dtype=tf.string)\n    \n    if PLOTTING_DISABLED:\n        return num_atoms, positions, elements, sample_atoms, sample_elements, geometria\n    \n    # 3D Visualization\n    fig = plt.figure(figsize=(8, 7))\n    ax = fig.add_subplot(111, projection='3d')\n    ax.scatter(positions[:, 0], positions[:, 1], positions[:, 2], s=50, c='cornflowerblue', label=f\"{element} Atoms\", edgecolors='k', alpha=0.8)\n    ax.set_xlabel('X (Å)')\n    ax.set_ylabel('Y (Å)')\n    ax.set_zlabel('Z (Å)')\n    ax.set_title(f'Spherical {element} Nanoparticle (FCC)')\n    ax.legend()\n    ax.set_aspect('equal', adjustable='box')\n    plt.tight_layout()\n    plt.show()\n\n    return num_atoms, positions, elements, sample_atoms, sample_elements, geometria","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.511797Z","iopub.execute_input":"2025-10-09T01:59:33.512144Z","iopub.status.idle":"2025-10-09T01:59:33.520862Z","shell.execute_reply.started":"2025-10-09T01:59:33.512122Z","shell.execute_reply":"2025-10-09T01:59:33.520176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Execute the full pipeline for Sample 2 and time it\nstart_time = time.time()\nsample_name = \"Al_dummy\"\n\nnum_atoms, positions, elements, sample_atoms, sample_elements, geometria = muestra_Al_dummy(celdas_largo, celdas_alto, celdas_profundidad, a)\npuntos_por_eje = 50\nnum_ni = 1\n\nStudies, Trials = optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=42)\nbest_study = optimization_results(Studies, Trials)\nion_final, ion_final_, starting_pos, loss_history, gradN_3D = training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, \n                                                                            params, param_tensors)\n_ = test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D,\n                params, param_tensors)\n\nend_time = time.time()\nexc_time = end_time - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.521496Z","iopub.execute_input":"2025-10-09T01:59:33.521737Z","iopub.status.idle":"2025-10-09T01:59:33.536650Z","shell.execute_reply.started":"2025-10-09T01:59:33.521722Z","shell.execute_reply":"2025-10-09T01:59:33.535952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total execution time for this sample: {exc_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.537385Z","iopub.execute_input":"2025-10-09T01:59:33.537579Z","iopub.status.idle":"2025-10-09T01:59:33.546609Z","shell.execute_reply.started":"2025-10-09T01:59:33.537561Z","shell.execute_reply":"2025-10-09T01:59:33.545897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.3. Sample 3: Armchair ZnO Nanotube","metadata":{}},{"cell_type":"code","source":"# Parameters for creating this sample\na = 1.872  # Zn-O bond length (Å)\nlongitud_objetivo = 16.02 # Target nanotube length (Å)\ndiametro_objetivo = 9.293 # Target nanotube diameter (Å)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.547387Z","iopub.execute_input":"2025-10-09T01:59:33.547569Z","iopub.status.idle":"2025-10-09T01:59:33.558279Z","shell.execute_reply.started":"2025-10-09T01:59:33.547555Z","shell.execute_reply":"2025-10-09T01:59:33.557541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Simulation parameter dictionary for this sample ---\n\n# Physical constants\nkj_mol_to_ev = 0.01034 # Conversion factor from kJ/mol to eV/atom\nk_e = 14.3996 # Coulomb's constant in (eV * Å / e^2)\n\n# Master dictionary containing all simulation parameters\nparams = {\n    'atom_types': [\"Zn\", \"O\", \"Ni\"], # Defines the order for parameter matrices\n    'ion_type': 'Ni', # Specifies which atom type is the adsorbing ion\n\n    # Per-atom parameters: sigma (van der Waals radius, Å), epsilon (potential well depth, eV), q (partial charge, e)\n    'atom_params': {\n        'Zn': {\"sigma\": 4.045, \"epsilon\": 0.23 * kj_mol_to_ev, \"q\": 0.86},\n        'O': {\"sigma\": 3.71, \"epsilon\": 1.736 * kj_mol_to_ev, \"q\": -0.86},\n        'Ni': {\"sigma\": 2.834, \"epsilon\": 0.0628 * kj_mol_to_ev, \"q\": 2}\n    },\n    \n    'coulomb_constant': k_e\n}\n\n# --- Build cross-interaction parameter matrices using Lorentz-Berthelot mixing rules ---\nnum_types = len(params['atom_types'])\natom_types = params['atom_types']\n\nsigma_matrix = [[0.0] * num_types for _ in range(num_types)]\nepsilon_matrix = [[0.0] * num_types for _ in range(num_types)]\ncutoff_matrix = [[0.0] * num_types for _ in range(num_types)]\n\nfor i in range(num_types):\n    for j in range(num_types):\n        type1, type2 = atom_types[i], atom_types[j]\n        sigma1, epsilon1 = params['atom_params'][type1]['sigma'], params['atom_params'][type1]['epsilon']\n        sigma2, epsilon2 = params['atom_params'][type2]['sigma'], params['atom_params'][type2]['epsilon']\n        \n        # Lorentz-Berthelot mixing rules\n        mixed_sigma = (sigma1 + sigma2) / 2.0\n        mixed_epsilon = (epsilon1 * epsilon2)**0.5\n        \n        sigma_matrix[i][j] = mixed_sigma\n        epsilon_matrix[i][j] = mixed_epsilon\n        cutoff_matrix[i][j] = 2.5 * mixed_sigma # Cutoff is typically 2.5 * sigma\n\n# Convert parameters to TensorFlow tensors for use in decorated functions\nparam_tensors = {\n    'type_map': tf.lookup.StaticHashTable(\n        initializer=tf.lookup.KeyValueTensorInitializer(\n            keys=tf.constant(atom_types, dtype=tf.string),\n            values=tf.constant(list(range(num_types)), dtype=tf.int32)\n        ),\n        default_value=tf.constant(-1, dtype=tf.int32)\n    ),\n    'q': tf.constant([params['atom_params'][t]['q'] for t in atom_types], dtype=tf.float32),\n    'sigma_matrix': tf.constant(sigma_matrix, dtype=tf.float32),\n    'epsilon_matrix': tf.constant(epsilon_matrix, dtype=tf.float32),\n    'cutoff_matrix': tf.constant(cutoff_matrix, dtype=tf.float32),\n    'k_e': tf.constant(params['coulomb_constant'], dtype=tf.float32)\n}","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.559116Z","iopub.execute_input":"2025-10-09T01:59:33.559339Z","iopub.status.idle":"2025-10-09T01:59:33.574510Z","shell.execute_reply.started":"2025-10-09T01:59:33.559322Z","shell.execute_reply":"2025-10-09T01:59:33.573832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Sample building function ---\n\ndef muestra_ZnO_nanotubo(longitud_enlace, longitud_objetivo, diametro_objetivo):\n    \"\"\"\n    Generates a single-walled \"Armchair\" type ZnO nanotube.\n\n    The structure is built by defining a 2D sheet unit cell and then rolling it\n    into a cylinder. The final dimensions may vary slightly from the targets\n    to maintain a perfect periodic structure.\n    \"\"\"\n    geometria = \"3D\"\n    a = longitud_enlace\n\n    # --- STEP 1: Define the 2D unit cell for an armchair sheet ---\n    # For an armchair nanotube, the sheet's Y-axis becomes the circumference\n    # and the X-axis becomes the tube's axial direction.\n    vec_axial = np.array([a * np.sqrt(3), 0, 0])\n    vec_circ = np.array([0, 3 * a, 0])\n\n    # Atomic basis within the unit cell (4 atoms per cell)\n    base_atoms_pos = [\n        np.array([0, 0, 0]),                          # Zn1\n        np.array([0, a, 0]),                          # O1\n        np.array([a * np.sqrt(3)/2, 3*a/2, 0]),       # Zn2\n        np.array([a * np.sqrt(3)/2, 5*a/2, 0])        # O2\n    ]\n    base_atoms_elem = [\"Zn\", \"O\", \"Zn\", \"O\"]\n\n    # --- STEP 2: Calculate the required number of unit cells ---\n    n_axial = int(np.round(longitud_objetivo / vec_axial[0]))\n    longitud_real = n_axial * vec_axial[0]\n\n    circunferencia_objetivo = np.pi * diametro_objetivo\n    n_circ = int(np.round(circunferencia_objetivo / vec_circ[1]))\n    circunferencia_real = n_circ * vec_circ[1]\n\n    radio_real = circunferencia_real / (2 * np.pi)\n    diametro_real = 2 * radio_real\n\n    print(f\"--- Generated Nanotube Parameters ---\")\n    print(f\"Target Length: {longitud_objetivo:.2f} Å -> Actual Length: {longitud_real:.2f} Å ({n_axial} axial cells)\")\n    print(f\"Target Diameter: {diametro_objetivo:.2f} Å -> Actual Diameter: {diametro_real:.2f} Å ({n_circ} circumferential cells)\")\n    print(\"-------------------------------------\")\n\n    # --- STEP 3: Generate the flat 2D sheet coordinates ---\n    positions_planar, elements = [], []\n    for i in range(n_axial):\n        for j in range(n_circ):\n            origin = i * vec_axial + j * vec_circ\n            for k in range(len(base_atoms_pos)):\n                positions_planar.append(origin + base_atoms_pos[k])\n                elements.append(base_atoms_elem[k])\n    positions_planar = np.array(positions_planar)\n\n    # --- STEP 4: Apply the cylindrical mapping to roll the sheet ---\n    positions_nanotubo = np.zeros_like(positions_planar)\n    for i, pos in enumerate(positions_planar):\n        x_planar, y_planar, _ = pos\n        theta = y_planar / radio_real\n        positions_nanotubo[i] = [x_planar, radio_real * np.cos(theta), radio_real * np.sin(theta)]\n\n    # --- STEP 5: Finalize and return results ---\n    positions = positions_nanotubo\n    positions -= np.mean(positions, axis=0) # Center the nanotube at the origin\n    elements = np.array(elements)\n    num_atoms = len(positions)\n    sample_atoms = tf.convert_to_tensor(positions, dtype=tf.float32)\n    sample_elements = tf.convert_to_tensor(elements, dtype=tf.string)\n\n    if PLOTTING_DISABLED:\n        return num_atoms, positions, elements, sample_atoms, sample_elements, geometria\n        \n    # --- Visualization ---\n    fig = plt.figure(figsize=(10, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    colors = {\"Zn\": \"grey\", \"O\": \"blue\"}\n\n    for atom_type in set(elements):\n        idx = (elements == atom_type)\n        ax.scatter(positions[idx, 0], positions[idx, 1], positions[idx, 2],\n                   c=colors.get(atom_type, \"black\"), label=atom_type, s=150, edgecolors='k')\n\n    ax.set_xlabel(\"Axial Direction X (Å)\")\n    ax.set_ylabel(\"Y (Å)\")\n    ax.set_zlabel(\"Z (Å)\")\n    ax.set_title(f\"Generated ZnO Nanotube (D={diametro_real:.2f} Å, L={longitud_real:.2f} Å)\")\n    ax.legend()\n    ax.set_box_aspect([longitud_real, diametro_real, diametro_real]) \n    plt.tight_layout()\n    plt.show()\n\n    return num_atoms, positions, elements, sample_atoms, sample_elements, geometria","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.575190Z","iopub.execute_input":"2025-10-09T01:59:33.575345Z","iopub.status.idle":"2025-10-09T01:59:33.587320Z","shell.execute_reply.started":"2025-10-09T01:59:33.575333Z","shell.execute_reply":"2025-10-09T01:59:33.586681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Execute the full pipeline for Sample 3 and time it\nstart_time = time.time()\nsample_name = \"ZnO_nanotube\"\n\nnum_atoms, positions, elements, sample_atoms, sample_elements, geometria = muestra_ZnO_nanotubo(a, longitud_objetivo, diametro_objetivo)\npuntos_por_eje = 50\nnum_ni = 1\n\nStudies, Trials = optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=41)\nbest_study = optimization_results(Studies, Trials)\nion_final, ion_final_, starting_pos, loss_history, gradN_3D = training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, \n                                                                            params, param_tensors)\n_ = test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D,\n                params, param_tensors)\n\nend_time = time.time()\nexc_time = end_time - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.587922Z","iopub.execute_input":"2025-10-09T01:59:33.588134Z","iopub.status.idle":"2025-10-09T01:59:33.603324Z","shell.execute_reply.started":"2025-10-09T01:59:33.588109Z","shell.execute_reply":"2025-10-09T01:59:33.602592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total execution time for this sample: {exc_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.603956Z","iopub.execute_input":"2025-10-09T01:59:33.604191Z","iopub.status.idle":"2025-10-09T01:59:33.617007Z","shell.execute_reply.started":"2025-10-09T01:59:33.604172Z","shell.execute_reply":"2025-10-09T01:59:33.616361Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.4. Sample 4: Bulk TiO2 (anatasa)","metadata":{}},{"cell_type":"code","source":"# Parameters for creating this sample\n# --------------------------\na_mp = 3.784000  # Å (Materials Project reported a ~ 3.784 Å)\nc_mp = 9.514000  # Å (Materials Project reported c ~ 9.514 Å)\n# u(O) in conventional unit cell from MP:\nuO_conventional_mp = 0.457152\n# for the primitive cell-like basis (AFLOW-like) we use:\nz2 = uO_conventional_mp - 0.25  #The transformation from conventional to primitive cell for anatasa dictates this equivalence\n\n# If you need the conventional fractional positions directly, they are those from MP (not used directly here)\n# We build the primitive basis (AFLOW-style) but with lattice params from MP to keep DFT consistency.\n\n# Primitive vectors (body-centered tetragonal) — construidos a partir de la celda convencional (MP)\na1 = np.array([-0.5 * a_mp,  0.5 * a_mp,  0.5 * c_mp])\na2 = np.array([ 0.5 * a_mp, -0.5 * a_mp,  0.5 * c_mp])\na3 = np.array([ 0.5 * a_mp,  0.5 * a_mp, -0.5 * c_mp])\n\n# Repeticiones por defecto para la supercelda\ndefault_nx = 2\ndefault_ny = 2\ndefault_nz = 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Simulation parameter dictionary for this sample ---\n\n# Physical constants\nkj_mol_to_ev = 0.01034 # Conversion factor from kJ/mol to eV/atom\nk_e = 14.3996 # Coulomb's constant in (eV * Å / e^2)\n\n# Master dictionary containing all simulation parameters\nparams = {\n    'atom_types': [\"Ti\", \"O\", \"Ni\"], # Defines the order for parameter matrices\n    'ion_type': 'Ni', # Specifies which atom type is the adsorbing ion\n\n    # Per-atom parameters: sigma (van der Waals radius, Å), epsilon (potential well depth, eV), q (partial charge, e)\n    'atom_params': {\n        'Ti': {\"sigma\": 1.99, \"epsilon\": 13.79 * kj_mol_to_ev, \"q\": 2.248},\n        'O': {\"sigma\": 3.71, \"epsilon\": 1.736 * kj_mol_to_ev, \"q\": -0.86},\n        'Ni': {\"sigma\": 2.834, \"epsilon\": 0.0628 * kj_mol_to_ev, \"q\": 2}\n    },\n    \n    'coulomb_constant': k_e\n}\n\n# --- Build cross-interaction parameter matrices using Lorentz-Berthelot mixing rules ---\nnum_types = len(params['atom_types'])\natom_types = params['atom_types']\n\nsigma_matrix = [[0.0] * num_types for _ in range(num_types)]\nepsilon_matrix = [[0.0] * num_types for _ in range(num_types)]\ncutoff_matrix = [[0.0] * num_types for _ in range(num_types)]\n\nfor i in range(num_types):\n    for j in range(num_types):\n        type1, type2 = atom_types[i], atom_types[j]\n        sigma1, epsilon1 = params['atom_params'][type1]['sigma'], params['atom_params'][type1]['epsilon']\n        sigma2, epsilon2 = params['atom_params'][type2]['sigma'], params['atom_params'][type2]['epsilon']\n        \n        # Lorentz-Berthelot mixing rules\n        mixed_sigma = (sigma1 + sigma2) / 2.0\n        mixed_epsilon = (epsilon1 * epsilon2)**0.5\n        \n        sigma_matrix[i][j] = mixed_sigma\n        epsilon_matrix[i][j] = mixed_epsilon\n        cutoff_matrix[i][j] = 2.5 * mixed_sigma # Cutoff is typically 2.5 * sigma\n\n# Convert parameters to TensorFlow tensors for use in decorated functions\nparam_tensors = {\n    'type_map': tf.lookup.StaticHashTable(\n        initializer=tf.lookup.KeyValueTensorInitializer(\n            keys=tf.constant(atom_types, dtype=tf.string),\n            values=tf.constant(list(range(num_types)), dtype=tf.int32)\n        ),\n        default_value=tf.constant(-1, dtype=tf.int32)\n    ),\n    'q': tf.constant([params['atom_params'][t]['q'] for t in atom_types], dtype=tf.float32),\n    'sigma_matrix': tf.constant(sigma_matrix, dtype=tf.float32),\n    'epsilon_matrix': tf.constant(epsilon_matrix, dtype=tf.float32),\n    'cutoff_matrix': tf.constant(cutoff_matrix, dtype=tf.float32),\n    'k_e': tf.constant(params['coulomb_constant'], dtype=tf.float32)\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Sample building function ---\n\n# --------------------------\ndef basis_vectors_primitive_from_mp(a: float, c: float, z2_param: float):\n    \"\"\"\n    Basis vectors in Cartesian for the primitive cell (AFLOW-style),\n    but using lattice constants taken from Materials Project (mp-390).\n    Returns list of (pos_cartesian, element_symbol) for the primitive cell.\n    \"\"\"\n    # Following AFLOW primitive basis expressions (B1..B6) but with a,c from MP,\n    # and z2 = u_conv_mp - 0.25 to map conventional MP u -> primitive internal coordinate.\n    B1 = np.array([0.0, 3.0/4.0 * a, 1.0/8.0 * c])                     # Ti\n    B2 = np.array([1.0/2.0 * a, -1.0/4.0 * a, 3.0/8.0 * c])            # Ti\n    B3 = np.array([0.0, 1.0/4.0 * a, c * z2_param])                    # O\n    B4 = np.array([1.0/2.0 * a, 1.0/4.0 * a, c * (z2_param - 1.0/4.0)])# O\n    B5 = np.array([0.0, 3.0/4.0 * a, -c * z2_param])                   # O\n    B6 = np.array([1.0/2.0 * a, -1.0/4.0 * a, -c * (z2_param - 1.0/4.0)]) # O\n\n    basis = [\n        (B1, \"Ti\"),\n        (B2, \"Ti\"),\n        (B3, \"O\"),\n        (B4, \"O\"),\n        (B5, \"O\"),\n        (B6, \"O\"),\n    ]\n    return basis\n\ndef muestra_TiO2_anatasa(rows:int, cols:int, layers:int,\n                        a:float = a_mp, c:float = c_mp, z2_param:float = z2,\n                        nx:int = default_nx, ny:int = default_ny, nz:int = default_nz):\n    \"\"\"\n    Genera una supercelda (replicación de la celda primitiva construida a partir\n    de los parámetros de Materials Project mp-390).\n    Args:\n        rows, cols, layers: (opciones de interfaz compatibles con tu pipeline de entrada)\n            - En este ejemplo rows/cols/layers no controlan la replicación de la celda\n              primitiva; usamos nx,ny,nz para supercelda en vectores primitivos.\n            - Mantengo la firma similar a tu ejemplo ZnO para compatibilidad.\n        a,c,z2_param: parámetros de red (usualmente desde MP)\n        nx,ny,nz: replicaciones a lo largo de vectores primitivos a1,a2,a3\n    Returns:\n        num_atoms, positions (np.ndarray Nx3), elements (np.ndarray Nx),\n        sample_atoms (tf.Tensor Nx3), sample_elements (tf.Tensor Nx), geometria (str)\n    \"\"\"\n    # Construir basis (primitiva AFLOW-style) con parámetros MP\n    basis = basis_vectors_primitive_from_mp(a, c, z2_param)\n\n    # Replicación con vectores primitivos definidos arriba (a1,a2,a3)\n    positions = []\n    elements = []\n    for i in range(nx):\n        for j in range(ny):\n            for k in range(nz):\n                R = i * a1 + j * a2 + k * a3\n                for pos_cart, sym in basis:\n                    positions.append(tuple(pos_cart + R))\n                    elements.append(sym)\n\n    # Convertir a arrays y tensores como en tu pipeline\n    positions = np.array(positions, dtype=float)\n    elements = np.array(elements)\n\n    num_atoms = len(positions)\n    sample_atoms = tf.convert_to_tensor(positions, dtype=tf.float32)\n    sample_elements = tf.convert_to_tensor(elements.astype(str), dtype=tf.string)\n\n    geometria = \"bulk_mp390_prim_replica\"\n\n    if PLOTTING_DISABLED:\n        return num_atoms, positions, elements, sample_atoms, sample_elements, geometria\n\n    # Visualización simple (manteniendo estilo de tu ejemplo)\n    colors = {\"Ti\": \"orange\", \"O\": \"red\"}\n    fig = plt.figure(figsize=(8,6))\n    ax = fig.add_subplot(111, projection='3d')\n\n    for atom_type in np.unique(elements):\n        idx = [i for i,e in enumerate(elements) if e == atom_type]\n        pos = positions[idx]\n        ax.scatter(pos[:,0], pos[:,1], pos[:,2],\n                   color=colors.get(atom_type, \"black\"),\n                   label=atom_type, s=80, edgecolors='k')\n\n    ax.set_xlabel(\"X (Å)\"); ax.set_ylabel(\"Y (Å)\"); ax.set_zlabel(\"Z (Å)\")\n    ax.set_title(f\"TiO2 anatasa (mp-390) — supercelda {nx}x{ny}x{nz}\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n\n    return num_atoms, positions, elements, sample_atoms, sample_elements, geometria","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Execute the full pipeline for Sample 4 and time it\nstart_time = time.time()\nsample_name = \"TiO2_bulk_anatase\"\n\nnum_atoms, positions, elements, sample_atoms, sample_elements, geometria = muestra_ZnO_nanotubo(a, longitud_objetivo, diametro_objetivo)\npuntos_por_eje = 50\nnum_ni = 1\n\nStudies, Trials = optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=41)\nbest_study = optimization_results(Studies, Trials)\nion_final, ion_final_, starting_pos, loss_history, gradN_3D = training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, \n                                                                            params, param_tensors)\n_ = test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D,\n                params, param_tensors)\n\nend_time = time.time()\nexc_time = end_time - start_time","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Performance Scaling Analysis: Time and energy vs. System Size","metadata":{}},{"cell_type":"markdown","source":"**This section analyzes how the computation time scales with the number of atoms in the sample, and the estability of the system's energy, using the ZnO graphene-like layer as a test case.**","metadata":{}},{"cell_type":"code","source":"# Parameters for creating this sample (repeat ZnO graphene-like layer)\na_zno = 1.863  # Zn-O bond length (Å)\nbeta_zno = 30 * np.pi / 180 # Hexagon projection angle (radians)\ndist_x = 2 * a * np.cos(beta_zno)\ndist_y = a * np.sin(beta_zno)\noffset_x = dist_x / 2\ncols = 6\nrows = 6","metadata":{"id":"phxfC95mS7gy","trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.621062Z","iopub.execute_input":"2025-10-09T01:59:33.621270Z","iopub.status.idle":"2025-10-09T01:59:33.628619Z","shell.execute_reply.started":"2025-10-09T01:59:33.621255Z","shell.execute_reply":"2025-10-09T01:59:33.627942Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Repeat ZnO dictionary of parameters ---\n\n# Physical constants\nkj_mol_to_ev = 0.01034 # Conversion factor from kJ/mol to eV/atom\nk_e = 14.3996 # Coulomb's constant in (eV * Å / e^2)\n\n# Master dictionary containing all simulation parameters\nparams = {\n    'atom_types': [\"Zn\", \"O\", \"Ni\"], # Defines the order for parameter matrices\n    'ion_type': 'Ni', # Specifies which atom type is the adsorbing ion\n\n    # Per-atom parameters: sigma (van der Waals radius, Å), epsilon (potential well depth, eV), q (partial charge, e)\n    'atom_params': {\n        'Zn': {\"sigma\": 4.045, \"epsilon\": 0.23 * kj_mol_to_ev, \"q\": 0.86},\n        'O': {\"sigma\": 3.71, \"epsilon\": 1.736 * kj_mol_to_ev, \"q\": -0.86},\n        'Ni': {\"sigma\": 2.834, \"epsilon\": 0.0628 * kj_mol_to_ev, \"q\": 2}\n    },\n    \n    'coulomb_constant': k_e\n}\n\n# --- Build cross-interaction parameter matrices using Lorentz-Berthelot mixing rules ---\nnum_types = len(params['atom_types'])\natom_types = params['atom_types']\n\nsigma_matrix = [[0.0] * num_types for _ in range(num_types)]\nepsilon_matrix = [[0.0] * num_types for _ in range(num_types)]\ncutoff_matrix = [[0.0] * num_types for _ in range(num_types)]\n\nfor i in range(num_types):\n    for j in range(num_types):\n        type1, type2 = atom_types[i], atom_types[j]\n        sigma1, epsilon1 = params['atom_params'][type1]['sigma'], params['atom_params'][type1]['epsilon']\n        sigma2, epsilon2 = params['atom_params'][type2]['sigma'], params['atom_params'][type2]['epsilon']\n        \n        # Lorentz-Berthelot mixing rules\n        mixed_sigma = (sigma1 + sigma2) / 2.0\n        mixed_epsilon = (epsilon1 * epsilon2)**0.5\n        \n        sigma_matrix[i][j] = mixed_sigma\n        epsilon_matrix[i][j] = mixed_epsilon\n        cutoff_matrix[i][j] = 2.5 * mixed_sigma # Cutoff is typically 2.5 * sigma\n\n# Convert parameters to TensorFlow tensors for use in decorated functions\nparam_tensors = {\n    'type_map': tf.lookup.StaticHashTable(\n        initializer=tf.lookup.KeyValueTensorInitializer(\n            keys=tf.constant(atom_types, dtype=tf.string),\n            values=tf.constant(list(range(num_types)), dtype=tf.int32)\n        ),\n        default_value=tf.constant(-1, dtype=tf.int32)\n    ),\n    'q': tf.constant([params['atom_params'][t]['q'] for t in atom_types], dtype=tf.float32),\n    'sigma_matrix': tf.constant(sigma_matrix, dtype=tf.float32),\n    'epsilon_matrix': tf.constant(epsilon_matrix, dtype=tf.float32),\n    'cutoff_matrix': tf.constant(cutoff_matrix, dtype=tf.float32),\n    'k_e': tf.constant(params['coulomb_constant'], dtype=tf.float32)\n}","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.629247Z","iopub.execute_input":"2025-10-09T01:59:33.629425Z","iopub.status.idle":"2025-10-09T01:59:33.643190Z","shell.execute_reply.started":"2025-10-09T01:59:33.629411Z","shell.execute_reply":"2025-10-09T01:59:33.642556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loop to run the simulation for increasing system sizes and record execution time\n\nsize_steps = 15 # Maximum number of unit cells per dimension\nnum_samples_to_generate = 45 #aproximate amount of different sizes to test\nmax_size = size_steps -1\nsize_factors = np.logspace(np.log10(2), np.log10(max_size), num_samples_to_generate)\n# Lists to store results\nfull_time = []\ntraining_time = [] \ntotal_atoms = []\navg_energies = []\n\nk = 10 # Reduce k for faster runs during scaling test\n\nprev_num_atoms = set() # To avoid re-running identical sizes (e.g., 2x3x4 vs 4x3x2)\n\nsample_name = \"Scaling_test\"\n\n# Use the context manager to suppress all plots and prints inside this loop\nwith suppress_output():\n    for size_factor in size_factors:\n        rows = cols = int(round(size_factor))\n        full_start_time = time.time()\n                  \n        num_atoms, positions, elements, sample_atoms, sample_elements, geometria = muestra_ZnO_grafeno(rows,a_zno,dist_y,offset_x,cols,dist_x)\n                \n        # Skip if this number of atoms has already been processed\n        if num_atoms in prev_num_atoms or num_atoms == 0:\n            continue\n        prev_num_atoms.add(num_atoms)\n                \n        puntos_por_eje = 50\n        num_ni = 1\n                \n        Studies, Trials = optimization(positions, geometria, puntos_por_eje, k, num_ni, num_trials, params, param_tensors, random_seed=42)\n        best_study = optimization_results(Studies, Trials)\n                \n        training_time_start = time.time()\n        ion_final, ion_final_, starting_pos, loss_history, gradN_3D = training_loop(best_study, epochs,  positions, sample_atoms, sample_elements, \n                                                                                    params, param_tensors)\n        final_system_energy = test_and_review(sample_atoms, sample_elements, ion_final, num_atoms, num_ni, starting_pos, loss_history, elements, positions, ion_final_, gradN_3D,\n                        params, param_tensors)\n                \n        full_end_time = time.time()\n        training_exc_time = full_end_time - training_time_start\n        full_exc_time = full_end_time - full_start_time\n                \n        full_time.append(full_exc_time)\n        training_time.append(training_exc_time)\n        total_atoms.append(num_atoms)\n        avg_adsorption_energy = final_system_energy / num_ni\n        avg_energies.append(avg_adsorption_energy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T01:59:33.643827Z","iopub.execute_input":"2025-10-09T01:59:33.644011Z","execution_failed":"2025-10-09T02:00:10.653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**According to N.D.M. Hine et al. (2009), traditional DFT simulations scale with O(N³), while linear-scaling methods can achieve O(N), where N is the number of atoms. We will compare our results against these theoretical scaling laws.**\n\n*Reference: Hine, N.D.M., et al. \"Linear-scaling density-functional theory with tens of thousands of atoms.\" Computer Physics Communications, 2009. https://doi.org/10.1016/j.cpc.2008.12.023*","metadata":{}},{"cell_type":"code","source":"# Generate theoretical DFT scaling times for comparison\n# We anchor the starting time of DFT to our first measurement (t0 at n0 atoms)\ndft_time_cubic = []\ndft_time_linear = []\n\nif total_atoms:\n    n0 = total_atoms[0]\n    t0 = full_time[0]\n    for i in total_atoms:\n        cubic_time = t0 * (i / n0)**3.0\n        linear_time = t0 * (i / n0)\n        dft_time_cubic.append(cubic_time)\n        dft_time_linear.append(linear_time)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-09T02:00:10.654Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Plot the results of the scaling analysis**","metadata":{}},{"cell_type":"code","source":"#build a df with the results\n\nresults_df = pd.DataFrame({\n    'atoms': total_atoms,\n    'full_time': full_time,\n    'training_time': training_time,\n    'avg_energy': avg_energies,\n    'dft_time_cubic': dft_time_cubic,\n    'dft_time_linear': dft_time_linear\n})\n\n# Sort by number of atoms for a clean plot\nresults_df = results_df.sort_values(by='atoms').reset_index(drop=True)\n\n# --- The Time Plot ---\n\nplt.figure(figsize=(12, 7))\nplt.plot(results_df['atoms'], results_df['full_time'], label='PIRIS (Full Pipeline)', color='blue', marker='o')\nplt.plot(results_df['atoms'], results_df['training_time'], label='PIRIS (Training Only)', color='green', marker='x', linestyle='--')\nplt.plot(results_df['atoms'], results_df['dft_time_cubic'], label='Theoretical DFT O(N³)', color='red', linestyle=':')\nplt.plot(results_df['atoms'], results_df['dft_time_linear'], label='Theoretical DFT O(N)', color='orange', linestyle='-.')\n\nplt.xlabel(\"Number of Atoms in Sample\")\nplt.ylabel(\"Computation Time (seconds)\")\nplt.title(\"Computation Time Scaling: PIRIS vs. Theoretical DFT\")\nplt.legend()\nplt.yscale('log') # Use a log scale for time to better visualize scaling differences\nplt.xscale('log') # Use a log scale for atoms as well\nplt.grid(False)#, which=\"both\", ls=\"--\")\n\nplot_name = f'scaling_analysis_piris_vs_dft(time).pdf'\nfilePath = os.path.join(output_dir, plot_name)\nplt.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\nplt.show()\n\n# --- The Energy plot ---\nplt.figure(figsize=(12, 7))\nplt.plot(results_df['atoms'], results_df['avg_energy'], label='PIRIS Avg. Adsorption Energy', color='crimson', marker='o')\n\n# Add a horizontal line for the mean energy to show convergence\nmean_energy = results_df['avg_energy'].mean()\nplt.axhline(y=mean_energy, color='gray', linestyle='--', label=f'Mean Energy = {mean_energy:.4f} eV/ion')\n\nplt.xlabel(\"Number of Atoms in Sample\")\nplt.ylabel(\"Average Adsorption Energy (eV/ion)\")\nplt.title(\"Model Stability: Adsorption Energy vs. Sample Size\")\nplt.legend()\nplt.grid(True, which=\"both\", ls=\"--\")\n\nplot_name = f'scaling_analysis_piris_vs_dft(energy).pdf'\nfilePath = os.path.join(output_dir, plot_name)\nplt.savefig(filePath, format='pdf', bbox_inches='tight', dpi=300)\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-09T02:00:10.654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 8. Push Results to GitHub","metadata":{}},{"cell_type":"code","source":"# --- COMMIT AND PUSH ALL GENERATED IMAGES TO GITHUB ---\nprint(\"Committing and pushing changes to GitHub...\")\ntry:\n    # Configure git user for this specific commit\n    subprocess.run([\"git\", \"config\", \"user.name\", GITHUB_USER], check=True)\n    subprocess.run([\"git\", \"config\", \"user.email\", f\"{GITHUB_USER}@users.noreply.github.com\"], check=True)\n    \n    # Stage all new and modified files\n    subprocess.run([\"git\", \"add\", \".\"], check=True)\n    \n    # Create a descriptive commit message\n    commit_message = f\"[Kaggle Run] Add simulation results from {run_timestamp}\"\n    subprocess.run([\"git\", \"commit\", \"-m\", commit_message], check=True)\n    \n    # Push the commit to the main branch on GitHub\n    subprocess.run([\"git\", \"push\", \"origin\", \"main\"], check=True)\n    \n    print(\"Successfully pushed the generated images to GitHub!\")\n    \nexcept subprocess.CalledProcessError as e:\n    print(f\"An error occurred during the git process: {e}\")\n    print(\"STDERR:\", e.stderr)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-09T02:00:10.654Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Notes:\n- Each sample creation function (`muestra_...`) must return the same parameters as the examples(like atom positions and the geometry type string ('planar' or '3D')).\n- The `sample_name` global variable should be updated before each run to ensure output image files have unique, descriptive names.\n- Take note that the Kaliedo installation will fail if you try to run that cell multiple times without killing the enviroment.","metadata":{}}]}